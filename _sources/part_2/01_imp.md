# Intelligent Music Production

Intelligent music prodution is a research field that aims to develop algorithms that provide assistance in the process of recording, mixing, or mastering a musical production. The systems can range from being assisitive, providing feedback and recommendations, to completely autonomous wherein they could control the mixing consoles end-to-end or based on certain criteria or conditioning. The field focuses not only on automatic mixing systems but also on smart signal processing units that can be used to either transform or enhance audio signals. 

Several approaches have been taken for designing these kind of systems ranging from models that produce appropriate parameterization of the pre-existing signal processing devices like the mixing console to direct transformation systems that directly operate on the input to produce output. Both the types of systems have their own pros and cons. The end-to-end natured systems offer less control to the user, produce less interpretable results, however, offer the possibility for more creativity, expressivity and astonishing chanced-outcomes. 

## High-Level Aims

The advanced technology today has made creating, publishing and distributing content more affordable and simple than ever before. This has led to a positively increasing number of people becoming interested in creating art and putting it out to the world. Hence, the demand for smart sytems that produce quick, affordable, and quality results is also rising. There are two potential audience for these kind of systems, namely, the amateurs/hobbyists and the profesionals. The designed systems should ideally be able to cater to both the categories of users. This means that systems should be able to provide quick, affordable and quality results while offering enough control and interpretability. 

## History

For close to half a century, several attempts to design these kind of smart attempts have been made. The earliest of the known systems was presented by Dugan in 1975 at the AES Convention, Los angeles. He designed a simple system for automatic microphone mixing that aimed to control the gain of multiple microphones for speech adaptively by monitoring the level of other microphones without any feedback[]. These mixers, which have developed through the years and are still in use in the industry, are only intended to give straightforward control over the volume of several channels in situations where a skilled audio engineer is not necessary. However, the limited control and versatality that these systems offered made them not very useful in more complex applications. However after several years, an interest was observed in the field around 2000s when Pachet and Delerue developed a system design that allowed listeners to adjust the spatialization of a multitrack mix while meeting a set of constraints set by the audio engineer[]. This work framed multitrack mixing as an optimization problem, which influenced the work done in the field for the years to come. 

The approaches taken for the system design from then to now can be categorised into three major brackets, namely, knowledge-based systems, machine learning-based systems and deep learning-based systems. 

## Approaches


### Knowledge-based Systems

The earliest works posed various multitrack mixing tasks as an optimisation problem that aimed at reducing perceptual masking. The expert knowledge was used to define certain rules that controlled the system to function in the desired manner. Most of these systems had two signal paths: the main signal path, which applied the transformation, and the side-chain, that aimed at analysing and extracting features from the incoming signal and generating conditional information that directed the main signal path to apply the transformation in a specific manner[]. The main signal path was optimised based on an optimisation algorithm or a rule base. Most of these systems were based on the assumption that perceptual models used for masking were representative of human perception and the set of underlying rules and constraints truly aligned with the internal goal of mixing engineers.

*~Diagram~ [knowledge-based systems]*

In 2007, an autonomous sytem for panning multitracks in a multitrack mixture was proposed []. Through a straightforward prioritisation structure and a filter bank of K filters that assess the energy inside each band of each input, this method seeks to lessen spectral masking among K input tracks. With the intention of eliminating spectral masking by spacing apart sources with comparable spectral content, these values are then utilised to guide the panning of each source over various panning steps in the stereo field. Thereafter, other tasks associated with multitrack mixing like balance[], equalisaion[], delay correction[] were also optimised in similar way. Though these systems were state-of-the-art at that time, they still lacked versatility to be able to cater to the entire spectrum of the real world projects and were very sensitive to the parameter tuning. Perez Gonzalez incorporated all these systems into one unified system and presented in his PhD thesis[]. The next few years saw attempts in improving the performance and accuracy of perceptual models. Some researchers also examined approaches that sought to achieve an equal loudness criteria across input channels were also examined, in addition to the objective of decreasing spectral masking within a mix[][][]. More through examination of the mixing practices were also conducted by some researchers to improve the rule base, thus improving the performance of knowledge-based sytems[].  All in all, these systems produced explainable results but couldn’t adapt well to the complexities of real world projects. 

### Classical Machine Learning

With the popularity of machine learning in the early 21st century, some researchers began to explore these directions for multitrack mixing system. These systems leverage large amount of parametric data collected from pros to train systems to do a specific task. Kolasinski[] utilised genetic algorithm and extracted audio features for leveling tracks[]. Scott et al utilized linear dynamical systems to predict time varying gains based on extracted audio features and a dataset of mutlitrack mixes[]. Investigations were also made into designing more complex processing units like dynamic range compression[], reverberation[], and equalisation[] which was not possible with knowledge-based systems.

However, the lack of availability of enough parametric data (parameter values for the processor along with the dry and processed audio) proved to be a limitation in the further development of this field. 

### Deep Learning Systems

In the recent years, the advancement in the deep learning-based approaches have given a new framework for approaching the multitrack mixing problem. Through the use of several layers of parameterized computations, the machine learning area of deep learning offers a framework for learning complicated, nonlinear relationships from data. These methods are often characterised by the use of neural network designs with numerous layers, the optimization of parameters using an appropriate loss function, stochastic gradient descent, and backpropagation. We train models that develop more potent representations that are tailored for the task at hand instead of employing features that are hand-crafted for each sort of input data and task as in earlier machine learning approaches. 

Deep learning based approaches heavily rely on the data used for training. However, the lack of availability of copyright-free multitrack data has been the major challenge in designing systems using these approaches. Deep learning based approaches used in audio domain are mostly inspired by the successful models in the computer vision domain. This means that the audio data is converted into a STFT(Short time fourier transform) before being processed like an image. The transformation produces a STFT as the output which needs to be converted back to an audio. This approach has the limitation in the sense that the phase information is lost in the process. Even though algorithms like the Griffin-Lim algorithm do a good job at reconstructing the phase information, the results sometimes still end up having undesirable artifacts. Another class of approaches directly work on audio and predict audio as outputs. The model is allowed to discover the best representations of the audio waveforms directly, unlike earlier spectrogram-based methods, which required intermediary, hand-designed representations to be created during pre- and post-processing. However, these models require a lot more computing resources to train and perform well. 

Some of the notable works using this approach have involved either implementing full-on end-to-end mixing systems or emulating audio effects using various methods to make them differentiable. 

## Considerations

Some important considerations for an automatic mixing system include interpretability, controllability, efficiency, permutation invariance, the requirement for specific input taxonomy, ability to handle a varying number of input recordings, fidelity, and the expressivity of the signal manipulation in mix creation. There are a lot of details to unpack there. Let’s introduce these eight considerations as we will keep them in mind as we discuss the details of different approaches in the following sections.

*Interpretability*: While it might not be critical to have a fully explainable model (in the XAI sense~\cite{}), it is often desirable for an automatic mixing system to convey what kind of manipulation is applied to each input recording in the creation of the mix. For example, this can easily be achieved by parameter estimation approaches, but is somewhat problematic for direct transformation approaches. 

*Controllability*: Similar to interpretability, a system with a level of controllability will enable the user to not only understand what signal transformations have been applied, but also enable adjustment of these transformations. Again, parameter estimation approaches enable this behavior by default, but direct transformation methods could also achieve controllability if they incorporate specialized conditioning mechanisms in the model.

*Context*: Closely related to controllability, although distinct, is the notion of context, or context-aware systems {cite}`lefford2021context`. As discussed in Section 1, context plays a central role in shaping the final outcome in the audio production process. As a result, it is important to consider to what degree an automatic mixing system is capable of understanding and adapting to the context. 

*Permutation Invariance*: An important realization is that the input recordings provided to the system are an unordered set. This means that the order in which the recordings are provided to our system should ideally not change the results. Some systems address this by adopting a fixed input taxonomy, but this restricts the system flexibility. Other approaches might deal with this by treating the input recordings as a set, often achieving this with weight sharing across the input recordings. We will discuss this further in the following sections.

*Input taxonomy*: As alluded to in the previous point, it is often beneficial to define a fixed input taxonomy. This means the system is trained using a dataset and model where the kind and number of sources that are passed to the system are fixed during training and inference. For example, in a system that mixes drum recordings, the inputs might always be presented to the system as an ordered set: “kick, snare, hi-hat, overhead left, overhead right, tom 1, tom 2”. While this often makes the process of creating an automatic mixing system simpler, it limits the ability of the system to be deployed in real-world scenarios wherein there exists limited structure with regards to the input recordings.

*Number of inputs*: Closely related to the input taxonomy is how the system handles a variable number of input recordings. Some systems might handle this by simply defining a maximum number of input recordings, inserting silence when an example contains fewer than the maximum. Other approaches that utilize weight sharing can potentially work around this and adapt to a variable number of sources, even those greater than seen during training since they treat the input recordings as a set and not a fixed vector. 

*Fidelity*: In audio engineering providing transformations to the sound that limit noise and distortion is critical. While noise, distortion, and other destructive transformations have applications in music production, the default assumption is that systems for processing audio signals will not impact unwanted artifacts. This is an important consideration as the utility of our automatic mixing system is largely dependent on the ability to produce a desirable mixture to the user that contains no audible artifacts.

*Expressivity*: An important consideration is to ensure that the process employed to create a mixture in the automatic mixing system is capable of producing the mix in the dataset. This can be a challenge for parameter estimation models.