# Intelligent Music Production

Intelligent music prodution is a esearch field that aims to develop algorithms that provide assistance in the process of recording, mixing, or mastering a musical production. The systems can range from being assisitive, providing feedback and recommendations, to completely autonomous wherein they could control the mixing consoles end-to-end or based on certain criteria or conditioning. The field focuses not only on automatic mixing systems but also on smart signal processing units that can be used to either transform or enhance audio signals. 

Several approaches have been taken for designing these kind of systems ranging from models that produce appropriate parameterization of the pre-existing signal processing devices like the mixing console to direct transformation systems that directly operate on the input to produce output. Both the types of systems have their own pros and cons. The end-to-end natured systems offer less control to the user, produce less interpretable results, however, offer the possibility for more creativity, expressivity and astonishing chanced-outcomes. 

## High-Level Aims

The advanced technology today has made creating, publishing and distributing content more affordable and simple than ever before. This has led to a positively increasing number of people becoming interested in creating art and putting it out to the world. Hence, the demand for smart sytems that produce quick, affordable, and quality results is also rising. There are two potential audience for these kind of systems, namely, the amateurs/hobbyists and the profesionals. The designed systems should ideally be able to cater to both the categories of users. This means that systems should be able to provide quick, affordable and quality results while offering enough control and interpretability. 

## History

For close to half a century, several attempts to design these kind of smart attempts have been made. The earliest of the known systems was presented by Dugan in 1975 at the AES Convention, Los angeles. He designed a simple system for automatic microphone mixing that aimed to control the gain of multiple microphones for speech adaptively by monitoring the level of other microphones without any feedback[]. These mixers, which have developed through the years and are still in use in the industry, are only intended to give straightforward control over the volume of several channels in situations where a skilled audio engineer is not necessary. However, the limited control and versatality that these systems offered made them not very useful in more complex applications. However after several years, an interest was observed in the field around 2000s when Pachet and Delerue developed a system design that allowed listeners to adjust the spatialization of a multitrack mix while meeting a set of constraints set by the audio engineer[]. This work framed multitrack mixing as an optimization problem, which influenced the work done in the field for the years to come. 

The approaches taken for the system design from then to now can be categorised into three major brackets, namely, knowledge-based systems, machine learning-based systems and deep learning-based systems. 

## Approaches


### Knowledge-based Systems

The earliest works posed various multitrack mixing tasks as an optimisation problem that aimed at reducing perceptual masking. The expert knowledge was used to define certain rules that controlled the system to function in the desired manner. Most of these systems had two signal paths: the main signal path, which applied the transformation, and the side-chain, that aimed at analysing and extracting features from the incoming signal and generating conditional information that directed the main signal path to apply the transformation in a specific manner[]. The main signal path was optimised based on an optimisation algorithm or a rule base. Most of these systems were based on the assumption that perceptual models used for masking were representative of human perception and the set of underlying rules and constraints truly aligned with the internal goal of mixing engineers.

*~Diagram~ [knowledge-based systems]*

In 2007, an autonomous sytem for panning multitracks in a multitrack mixture was proposed []. Through a straightforward prioritisation structure and a filter bank of K filters that assess the energy inside each band of each input, this method seeks to lessen spectral masking among K input tracks. With the intention of eliminating spectral masking by spacing apart sources with comparable spectral content, these values are then utilised to guide the panning of each source over various panning steps in the stereo field. Thereafter, other tasks associated with multitrack mixing like balance[], equalisaion[], delay correction[] were also optimised in similar way. Though these systems were state-of-the-art at that time, they still lacked versatility to be able to cater to the entire spectrum of the real world projects and were very sensitive to the parameter tuning. Perez Gonzalez incorporated all these systems into one unified system and presented in his PhD thesis[]. The next few years saw attempts in improving the performance and accuracy of perceptual models. Some researchers also examined approaches that sought to achieve an equal loudness criteria across input channels were also examined, in addition to the objective of decreasing spectral masking within a mix[][][]. More through examination of the mixing practices were also conducted by some researchers to improve the rule base, thus improving the performance of knowledge-based sytems[].  All in all, these systems produced explainable results but couldnâ€™t adapt well to the complexities of real world projects. 

### Classical Machine Learning

With the popularity of machine learning in the early 21st century, some researchers began to explore these directions for multitrack mixing system. These systems leverage large amount of parametric data collected from pros to train systems to do a specific task. Kolasinski[] utilised genetic algorithm and extracted audio features for leveling tracks[]. Scott et al utilized linear dynamical systems to predict time varying gains based on extracted audio features and a dataset of mutlitrack mixes[]. Investigations were also made into designing more complex processing units like dynamic range compression[], reverberation[], and equalisation[] which was not possible with knowledge-based systems.

However, the lack of availability of enough parametric data (parameter values for the processor along with the dry and processed audio) proved to be a limitation in the further development of this field. 

### Deep Learning Systems

In the recent years, the advancement in the deep learning-based approaches have given a new framework for approaching the multitrack mixing problem. Through the use of several layers of parameterized computations, the machine learning area of deep learning offers a framework for learning complicated, nonlinear relationships from data. These methods are often characterised by the use of neural network designs with numerous layers, the optimization of parameters using an appropriate loss function, stochastic gradient descent, and backpropagation. We train models that develop more potent representations that are tailored for the task at hand instead of employing features that are hand-crafted for each sort of input data and task as in earlier machine learning approaches. 

Deep learning based approaches heavily rely on the data used for training. However, the lack of availability of copyright-free multitrack data has been the major challenge in designing systems using these approaches. Deep learning based approaches used in audio domain are mostly inspired by the successful models in the computer vision domain. This means that the audio data is converted into a STFT(Short time fourier transform) before being processed like an image. The transformation produces a STFT as the output which needs to be converted back to an audio. This approach has the limitation in the sense that the phase information is lost in the process. Even though algorithms like the Griffin-Lim algorithm do a good job at reconstructing the phase information, the results sometimes still end up having undesirable artifacts. Another class of approaches directly work on audio and predict audio as outputs. The model is allowed to discover the best representations of the audio waveforms directly, unlike earlier spectrogram-based methods, which required intermediary, hand-designed representations to be created during pre- and post-processing. However, these models require a lot more computing resources to train and perform well. 

Some of the notable works using this approach have involved either implementing full-on end-to-end mixing systems or emulating audio effects using various methods to make them differentiable. 
