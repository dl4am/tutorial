
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Listening Tests &#8212; Deep Learning for Automatic Mixing</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Evaluation" href="03_evaluate.html" />
    <link rel="prev" title="Evaluation" href="01_evaluation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep Learning for Automatic Mixing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../landing-page.html">
                    Deep Learning for Automatic Mixing 
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Audio Engineering
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../part_1/01_music-production.html">
   Music Production
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../part_1/02_audio-effects.html">
   Audio effects
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../part_1/audio-effects/01_panning.html">
     Panning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../part_1/audio-effects/02_equalization.html">
     Equalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../part_1/audio-effects/03_compression.html">
     Compression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../part_1/audio-effects/04_reverberation.html">
     Reverberation
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Automatic Mixing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../part_2/01_imp.html">
   Intelligent Music Production
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part_2/02_problem.html">
   Problem Formulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part_2/03_diffsp.html">
   Differentiable signal processing
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../part_2/04_methods.html">
   Methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../part_2/methods/01_mixwaveunet.html">
     Mix-Wave-U-Net
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../part_2/methods/02_dmc.html">
     Differentiable Mixing Console
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part_2/05_loss-functions.html">
   Loss Functions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Implementation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../part_3/01_inference.html">
   Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part_3/02_datasets.html">
   Datasets for automix systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part_3/03_models.html">
   Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part_3/04_training.html">
   Training
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Evaluation
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_evaluation.html">
   Evaluation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Listening Tests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_evaluate.html">
   Evaluation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Conclusion
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../part_5/01_future-directions.html">
   Future Directions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part_5/02_conclusion.html">
   Conclusions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part_5/03_references.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/dl4am/tutorial"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/dl4am/tutorial/issues/new?title=Issue%20on%20page%20%2Fpart_4/02_listening-tests.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/part_4/02_listening-tests.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#participants">
   Participants
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-tests">
   Types of Tests
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mushra">
     MUSHRA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ape">
     APE
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#criteria">
   Criteria
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advice">
   Advice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#platforms">
   Platforms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#web-audio-evaluation-tool">
     Web Audio Evaluation Tool
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     webMUSHRA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#golisten">
     goListen
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#challenges">
   Challenges
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Listening Tests</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#participants">
   Participants
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-tests">
   Types of Tests
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mushra">
     MUSHRA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ape">
     APE
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#criteria">
   Criteria
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advice">
   Advice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#platforms">
   Platforms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#web-audio-evaluation-tool">
     Web Audio Evaluation Tool
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     webMUSHRA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#golisten">
     goListen
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#challenges">
   Challenges
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="listening-tests">
<h1>Listening Tests<a class="headerlink" href="#listening-tests" title="Permalink to this headline">#</a></h1>
<p>When designing listening tests for automatic music mixing systems, several criteria must be taken into account, such as the type of test, the number of stimuli, the duration of the stimuli, the criteria to be rated, the requirements for the participants, the listening environment, etc. While there is no standard, pre-defined testing method, we provide a set of best practices that can be tailored based on the requirements of the mixing system being tested.</p>
<section id="participants">
<h2>Participants<a class="headerlink" href="#participants" title="Permalink to this headline">#</a></h2>
<p>Due to the high level of detail inherent within the perceived difference between mixes, it is preferable that participants have experience in music mixing, or at least music making or critical listening activities. Participants without such experience are likely to be unable to perceive production differences between mixes, making their ratings unreliable.</p>
<p>The preferable listening setup for this type of test is in a listening room with high-quality professional monitors. This is because this is the most common setting used by mixing engineers when creating or analyzing mixes. When a room with professional sound installation is not available, the use of high-quality headphones is often preferred.</p>
<p>However, it is worth noting that when listening to speakers compared to headphones, the stereo image changes, that is, when using headphones, the sound sources are placed “inside the head” <span id="id1">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>. Moreover, most of the professional mixing engineers will mix using speakers. Therefore, it is important to consider this when one of the aspects to be rated is the stereo image. A good practice is to test exclusively with speakers or headphones, but not allow both listening configurations within the same test.</p>
</section>
<section id="types-of-tests">
<h2>Types of Tests<a class="headerlink" href="#types-of-tests" title="Permalink to this headline">#</a></h2>
<p>Multi-stimulus tests are often preferred over pairwise or single stimulus tests. Single stimulus tests, such as the Mean Opinion Score (MOS) test, are generally used to rate the overall quality of a stimulus, thus focusing on the content properties of the source material. Conversely, when evaluating the production quality of various mixes, it is preferable for participants to focus on the contrasting mix properties between mixes rather than on the content material of the mixes <span id="id2">[<a class="reference internal" href="../part_5/03_references.html#id130" title="Esben Skovenborg. Development of semantic scales for music mastering. In Audio Engineering Society Convention 141. 2016.">Sko16</a>]</span>. Also, as the number of mixtures to be compared increases, it has been found that pairwise tests tend to be less reliable and discriminatory <span id="id3">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>.</p>
<p>The most common types of multi-stimulus tests are the following:</p>
<section id="mushra">
<h3>MUSHRA<a class="headerlink" href="#mushra" title="Permalink to this headline">#</a></h3>
<p>Multiple Stimuli with Hidden Reference and Anchor (MUSHRA) is a well-known testing method initially designed for measuring the perceptual quality of audio codecs. Although this method is widely used in various audio and music perception tasks, the inherent design constraints of the method represent several limitations when evaluating music mixes.</p>
<p>For instance, given the subjective task at hand, having a professional human-made mix as reference can be problematic, as even commercial mixes made by renown engineers are not always rated highly <span id="id4">[<a class="reference internal" href="../part_5/03_references.html#id131" title="Brecht De Man. Towards a better understanding of mix engineering. PhD thesis, Queen Mary University of London, 2017.">DM17</a>, <a class="reference internal" href="../part_5/03_references.html#id75" title="Marco A Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Stefan Uhlich, Chihiro Nagashima, and Yuki Mitsufuji. Automatic music mixing with deep learning and out-of-domain data. In ISMIR. 2022.">MartinezRamirezLF+22</a>, <a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>. Thus, when the stimulus has the potential to outperform the reference or hidden anchor, the MUSHRA methodology is not recommended <span id="id5">[<a class="reference internal" href="../part_5/03_references.html#id129" title="Rec ITU-R. ITU-R BS. 1534-3, method for the subjective assessment of intermediate quality level of audio systems. International Telecommunications Union, Geneva, 2015.">IR15</a>]</span>.
Furthermore, we often test mixes for overall production quality or technical preference and not for their similarity to a reference mix, hence rendering the use of a hidden anchor reference as unnecessary.</p>
<p>Regarding the use of low and mid anchors, when the participants are experts, the use of such anchors might have a negative impact on the test results. This is due to the critical listening skills of experts, whose discrimination of a low anchor, such as a monaural or random processed mix, is trivial. Thus, the presence of a low anchor will tend to compress the ratings of the other stimuli and could distract participants from focusing on the significant contrastive differences within the mixtures <span id="id6">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>. Another argument for not including the anchor is to reduce the number of stimuli and thus allowing tests with a larger number of mixtures to be tested. It should be noted that when the participants are not exclusively experts, the use of low and mid anchors can serve its beneficial original purpose within the test.</p>
<p>Finally, the MUSHRA method recommends using stimuli of no more than 12 seconds, which, based on empirical data, we have found that experts consider this duration to be too short to adequately assess quality within a set of mixtures.</p>
<p>In general, it is not recommended to fully follow the MUSHRA methodology for the evaluation of this task, however, this multi-stimulus methodology could be further modified to fit the specific needs for the evaluation of automatic mixing systems.</p>
<figure class="align-center" id="webmushra">
<a class="reference internal image-reference" href="../_images/webmushra.svg"><img alt="../_images/webmushra.svg" src="../_images/webmushra.svg" width="70%" /></a>
<figcaption>
<p><span class="caption-number">Fig. 24 </span><span class="caption-text">MUSHRA test implemented with webMUSHRA <span id="id7">[<a class="reference internal" href="../part_5/03_references.html#id112" title="Michael Schoeffler, Sarah Bartoschek, Fabian-Robert Stöter, Marlene Roess, Susanne Westphal, Bernd Edler, and Jürgen Herre. Webmushra—a comprehensive framework for web-based listening tests. Journal of Open Research Software, 2018.">SBStoter+18</a>]</span>.</span><a class="headerlink" href="#webmushra" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="go-listen">
<a class="reference internal image-reference" href="../_images/go-listen.svg"><img alt="../_images/go-listen.svg" src="../_images/go-listen.svg" width="70%" /></a>
<figcaption>
<p><span class="caption-number">Fig. 25 </span><span class="caption-text">MUSHRA test implemented with goListen <span id="id8">[<a class="reference internal" href="../part_5/03_references.html#id133" title="Dan Barry, Qijian Zhang, Pheobe Wenyi Sun, and Andrew Hines. Go listen: an end-to-end online listening test platform. Journal of Open Research Software, 2021.">BZSH21b</a>]</span>.</span><a class="headerlink" href="#go-listen" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="ape">
<h3>APE<a class="headerlink" href="#ape" title="Permalink to this headline">#</a></h3>
<p>As an alternative for multi-stimulus testing the Audio Perceptual Evaluation (APE) was proposed by <span id="id9">[<a class="reference internal" href="../part_5/03_references.html#id141" title="Brecht De Man and Joshua D Reiss. APE: audio perceptual evaluation toolbox for MATLAB. In Audio Engineering Society Convention 136. 2014.">DMR14</a>]</span>.
The main difference with the MUSHRA method is that all the stimuli are placed under the same continuous horizontal line, thus allowing instant visualization of the ratings. Also, the use of reference and anchor is optional as well as the maximum length of the stimuli.
Examples of APE testing interface used in recent automatic music mixing systems:</p>
<figure class="align-center" id="ape-dmc">
<a class="reference internal image-reference" href="../_images/APE_DMC.svg"><img alt="../_images/APE_DMC.svg" src="../_images/APE_DMC.svg" width="70%" /></a>
<figcaption>
<p><span class="caption-number">Fig. 26 </span><span class="caption-text">APE test from <span id="id10">[<a class="reference internal" href="../part_5/03_references.html#id139" title="Christian J. Steinmetz, Jordi Pons, Santiago Pascual, and Joan Serrà. Automatic multitrack mixing with a differentiable mixing console of neural audio effects. In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP). 2021.">SPPS21</a>]</span>.</span><a class="headerlink" href="#ape-dmc" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="ape-wun-drums">
<a class="reference internal image-reference" href="../_images/APE_WaveUNet_Drums.svg"><img alt="../_images/APE_WaveUNet_Drums.svg" src="../_images/APE_WaveUNet_Drums.svg" width="70%" /></a>
<figcaption>
<p><span class="caption-number">Fig. 27 </span><span class="caption-text">APE test from {cite}`martinez2021deep.</span><a class="headerlink" href="#ape-wun-drums" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="ape-fxnorm">
<a class="reference internal image-reference" href="../_images/APE_FxNorm.svg"><img alt="../_images/APE_FxNorm.svg" src="../_images/APE_FxNorm.svg" width="70%" /></a>
<figcaption>
<p><span class="caption-number">Fig. 28 </span><span class="caption-text">APE test from~\cite{martinez2022automatic}. For this test, dry stems were used as references. This is based on feedback from pilot tests and was proposed by the expert participants.</span><a class="headerlink" href="#ape-fxnorm" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="criteria">
<h2>Criteria<a class="headerlink" href="#criteria" title="Permalink to this headline">#</a></h2>
<p>The most common criterion used in multi-stimulus testing is to ask participants to rate various mixes according to their overall preference. This encompasses both technical and subjective criteria and is often based on a scale from 0 to 1 or from 0 to 100, with or without the use of semantic labels associated with a certain range of the numerical scale <span id="id11">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>.</p>
<p>When looking for more detailed and discriminatory perceptual ratings, the general preference criterion can be divided into Production Value, Clarity and Excitement as shown in <span id="id12">[<a class="reference internal" href="../part_5/03_references.html#id75" title="Marco A Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Stefan Uhlich, Chihiro Nagashima, and Yuki Mitsufuji. Automatic music mixing with deep learning and out-of-domain data. In ISMIR. 2022.">MartinezRamirezLF+22</a>, <a class="reference internal" href="../part_5/03_references.html#id29" title="Pedro D Pestana and Joshua D Reiss. A cross-adaptive dynamic spectral panning technique. In DAFx, 303–307. Erlangen, 2014.">PR14</a>]</span>, which are defined as follows:</p>
<ul class="simple">
<li><p><strong>Production Value</strong>: Technical quality of the mix. This corresponds to subjective preferences related to the overall technical quality of the mix, considering all the audio mixing characteristics; such as dynamics, EQ, balance, and stereo image.</p></li>
<li><p><strong>Clarity</strong>: Ability to differentiate musical sources. This is entirely objective and corresponds to the perceived presence or absence of masking.</p></li>
<li><p><strong>Excitement</strong> A non-technical subjective reaction to the mix. This is not related to an evaluation of quality, but to a more personal perception of novelty. Due to engaging, intriguing or thought-provoking aspects within the mix.</p></li>
</ul>
<p>It is worth noting that while the Clarity criterion measures the presence or absence of masking, this criterion is not objectively universal, and for certain genres or submixes, masking might be aesthetically desirable. However, Clarity can serve as an indicator for objective perceptual performance within mixes.</p>
</section>
<section id="advice">
<h2>Advice<a class="headerlink" href="#advice" title="Permalink to this headline">#</a></h2>
<p>The following are a set of general rules of thumb design decisions, and although they are not exhaustive, they can serve as a fundamental starting point when designing listening tests for automatic music mixing systems.</p>
<ul class="simple">
<li><p>Participants should be blind to the stimulus as much as possible, thus, participants must not be informed of the underlying methods to generate the mixes. The contrary could lead to a negative bias towards fully automated generated mixes.</p></li>
<li><p>Randomize the order of the stimuli and mixtures to be tested.</p></li>
<li><p>Results when participants have experience in mix engineering are more reliable.</p></li>
<li><p>Conduct a pilot listening test to get a clear idea of the approximate total duration and to recognize potential misunderstanding issues.</p></li>
<li><p>Always write detailed instructions and, if possible, also provide verbal instructions to the participants to minimize the risk of misunderstandings within the task.</p></li>
<li><p>Consider excluding participants if their total testing time is too short or if there are large deviations when compared to the other participants. However, when this occurs, please do report the exclusion of such participants.</p></li>
<li><p>Collect additional data, such as age, gender identity, years of mixing experience, and comments regarding the test. This could lead to additional insights and findings from the test.</p></li>
<li><p>The maximum total duration of a listening test in which listening fatigue does not affect the reliability of the results is 90 minutes {cite}`schatz2012impact}. However, such findings included a 10-minute break. Therefore, a recommendation is to keep the duration of the listening test under 45 minutes.</p></li>
<li><p>A training stage preceding the test may be beneficial to participants. This stage must be taken into account within the total duration of the test.</p></li>
<li><p>To assess various audio effects or mixing characteristics of mixes, experts prefer segments between 25 and 60 seconds. Typically, such a segment should cover a verse and a chorus or at least the transition between said musical parts.</p></li>
<li><p>Do not use a ground truth reference unless the specific task at hand deems it necessary.</p></li>
<li><p>Low and mid anchors tend not to be necessary if participants are skilled or experienced in mix engineering.</p></li>
<li><p>The number of stimuli per multi-stimulus test page must be less than 12 <span id="id13">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>.</p></li>
<li><p>If labels are assigned to the rating scale, they must be properly defined and explained to the participants. Examples of such labels can be “Bad, Poor, Fair, Good, Excellent”.</p></li>
<li><p>Participants prefer synchronized playback between stimuli so they can better focus on contrast differences between mixes.</p></li>
<li><p>Loudness should not influence the rated criteria. Therefore, samples must be loudness normalized, except for the cases where loudness is crucial to the criteria to be rated.</p></li>
<li><p>Participants must limit the times they adjust the volume of their listening settings. Ideally this should be done once and only at the beginning of the test. These instructions must be given to the participants.</p></li>
</ul>
</section>
<section id="platforms">
<h2>Platforms<a class="headerlink" href="#platforms" title="Permalink to this headline">#</a></h2>
<p>The following are the most common used platforms for perceptual listening tests:</p>
<section id="web-audio-evaluation-tool">
<h3>Web Audio Evaluation Tool<a class="headerlink" href="#web-audio-evaluation-tool" title="Permalink to this headline">#</a></h3>
<p><span id="id14">[<a class="reference internal" href="../part_5/03_references.html#id113">JMM+15</a>]</span></p>
<ul class="simple">
<li><p>APE and MUSHRA</p></li>
<li><p>Reference is optional</p></li>
<li><p>Training stage is possible</p></li>
<li><p>Loudness normalization within the platform</p></li>
<li><p>Synchronized playback</p></li>
<li><p>Customization requires effort</p></li>
</ul>
</section>
<section id="id15">
<h3>webMUSHRA<a class="headerlink" href="#id15" title="Permalink to this headline">#</a></h3>
<p><span id="id16">[<a class="reference internal" href="../part_5/03_references.html#id112" title="Michael Schoeffler, Sarah Bartoschek, Fabian-Robert Stöter, Marlene Roess, Susanne Westphal, Bernd Edler, and Jürgen Herre. Webmushra—a comprehensive framework for web-based listening tests. Journal of Open Research Software, 2018.">SBStoter+18</a>]</span></p>
<ul class="simple">
<li><p>MUSHRA</p></li>
<li><p>Training stage is possible</p></li>
<li><p>Fade-in/out within the platform</p></li>
<li><p>Synchronized playback</p></li>
<li><p>Customization requires effort</p></li>
</ul>
</section>
<section id="golisten">
<h3>goListen<a class="headerlink" href="#golisten" title="Permalink to this headline">#</a></h3>
<p><span id="id17">[<a class="reference internal" href="../part_5/03_references.html#id111" title="Dan Barry, Qijian Zhang, Pheobe Wenyi Sun, and Andrew Hines. Go listen: an end-to-end online listening test platform. Journal of Open Research Software, 2021. URL: http://doi.org/10.5334/jors.361.">BZSH21a</a>]</span></p>
<ul class="simple">
<li><p>MUSHRA</p></li>
<li><p>Reference is optional</p></li>
<li><p>Synchronized playback</p></li>
<li><p>Customization requires effort</p></li>
<li><p>Ease-of-use and implementation</p></li>
</ul>
</section>
</section>
<section id="challenges">
<h2>Challenges<a class="headerlink" href="#challenges" title="Permalink to this headline">#</a></h2>
<p>It is worth noting that another limitation of the objective and subjective evaluation methods discussed above is the inability to measure whether the generated mixes have long-temporal coherence. This is because a song’s mixing style is usually consistent throughout the song’s length—and often throughout the entire album or EP—so we should investigate whether automatic mixing systems produce mixes with this level of coherence, which means that methods to measure this long-temporal coherence must be researched. For example, evaluation systems that measure mixing style coherence within different song elements such as verses, choruses, and so on, could yield more accurate objective and subjective ways of evaluating generated mixes.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./part_4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="01_evaluation.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Evaluation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="03_evaluate.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Evaluation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Christian J. Steinmetz, Soumya Sai Vanka, Marco Martínez, Gary Bromham<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>