
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Listening Tests &#8212; Deep Learning for Automatic Mixing</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'part_4/02_listening-tests';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Evaluation" href="03_evaluate.html" />
    <link rel="prev" title="Evaluation" href="01_evaluation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../landing-page.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Deep Learning for Automatic Mixing - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Deep Learning for Automatic Mixing - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../landing-page.html">
                    Deep Learning for Automatic Mixing 
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Audio Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part_1/01_music-production.html">Music Production</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../part_1/02_audio-effects.html">Audio effects</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../part_1/audio-effects/01_panning.html">Panning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_1/audio-effects/02_equalization.html">Equalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_1/audio-effects/03_compression.html">Compression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_1/audio-effects/04_reverberation.html">Reverberation</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Automatic Mixing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part_2/01_imp.html">Intelligent Music Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_2/02_problem.html">Problem Formulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_2/03_diffsp.html">Differentiable signal processing</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../part_2/04_methods.html">Methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../part_2/methods/01_mixwaveunet.html">Mix-Wave-U-Net</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_2/methods/02_dmc.html">Differentiable Mixing Console</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_2/methods/03_diffmst.html">Differentable Mixing Style transfer</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../part_2/05_loss-functions.html">Loss Functions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Implementation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part_3/01_inference.html">Inference</a></li>

<li class="toctree-l1"><a class="reference internal" href="../part_3/02_datasets.html">Datasets for automix systems</a></li>


<li class="toctree-l1"><a class="reference internal" href="../part_3/03_models.html">Models</a></li>


<li class="toctree-l1"><a class="reference internal" href="../part_3/04_training.html">Training</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Evaluation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_evaluation.html">Evaluation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Listening Tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_evaluate.html">Evaluation</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Conclusion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part_5/01_future-directions.html">Future Directions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_5/02_conclusion.html">Conclusions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_5/03_references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/dl4am/tutorial" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/dl4am/tutorial/issues/new?title=Issue%20on%20page%20%2Fpart_4/02_listening-tests.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/part_4/02_listening-tests.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Listening Tests</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#participants">Participants</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-tests">Types of Tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mushra">MUSHRA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ape">APE</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#criteria">Criteria</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advice">Advice</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#platforms">Platforms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#web-audio-evaluation-tool">Web Audio Evaluation Tool</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">webMUSHRA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#golisten">goListen</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges">Challenges</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="listening-tests">
<h1>Listening Tests<a class="headerlink" href="#listening-tests" title="Link to this heading">#</a></h1>
<p>When designing listening tests for automatic music mixing systems, several criteria must be taken into account, such as the type of test, the number of stimuli, the duration of the stimuli, the criteria to be rated, the requirements for the participants, the listening environment, etc. While there is no standard, pre-defined testing method, we provide a set of best practices that can be tailored based on the requirements of the mixing system being tested.</p>
<section id="participants">
<h2>Participants<a class="headerlink" href="#participants" title="Link to this heading">#</a></h2>
<p>Due to the high level of detail inherent within the perceived difference between mixes, it is preferable that participants have experience in music mixing, or at least music making or critical listening activities. Participants without such experience are likely to be unable to perceive production differences between mixes, making their ratings unreliable.</p>
<p>The preferable listening setup for this type of test is in a listening room with high-quality professional monitors. This is because this is the most common setting used by mixing engineers when creating or analyzing mixes. When a room with professional sound installation is not available, the use of high-quality headphones is often preferred.</p>
<p>However, it is worth noting that when listening to speakers compared to headphones, the stereo image changes, that is, when using headphones, the sound sources are placed “inside the head” <span id="id1">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>. Moreover, most of the professional mixing engineers will mix using speakers. Therefore, it is important to consider this when one of the aspects to be rated is the stereo image. A good practice is to test exclusively with speakers or headphones, but not allow both listening configurations within the same test.</p>
</section>
<section id="types-of-tests">
<h2>Types of Tests<a class="headerlink" href="#types-of-tests" title="Link to this heading">#</a></h2>
<p>Multi-stimulus tests are often preferred over pairwise or single stimulus tests. Single stimulus tests, such as the Mean Opinion Score (MOS) test, are generally used to rate the overall quality of a stimulus, thus focusing on the content properties of the source material. Conversely, when evaluating the production quality of various mixes, it is preferable for participants to focus on the contrasting mix properties between mixes rather than on the content material of the mixes <span id="id2">[<a class="reference internal" href="../part_5/03_references.html#id130" title="Esben Skovenborg. Development of semantic scales for music mastering. In Audio Engineering Society Convention 141. 2016.">Sko16</a>]</span>. Also, as the number of mixtures to be compared increases, it has been found that pairwise tests tend to be less reliable and discriminatory <span id="id3">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>.</p>
<p>The most common types of multi-stimulus tests are the following:</p>
<section id="mushra">
<h3>MUSHRA<a class="headerlink" href="#mushra" title="Link to this heading">#</a></h3>
<p>Multiple Stimuli with Hidden Reference and Anchor (MUSHRA) is a well-known testing method initially designed for measuring the perceptual quality of audio codecs. Although this method is widely used in various audio and music perception tasks, the inherent design constraints of the method represent several limitations when evaluating music mixes.</p>
<p>For instance, given the subjective task at hand, having a professional human-made mix as reference can be problematic, as even commercial mixes made by renown engineers are not always rated highly <span id="id4">[<a class="reference internal" href="../part_5/03_references.html#id131" title="Brecht De Man. Towards a better understanding of mix engineering. PhD thesis, Queen Mary University of London, 2017.">DM17</a>, <a class="reference internal" href="../part_5/03_references.html#id75" title="Marco A Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Stefan Uhlich, Chihiro Nagashima, and Yuki Mitsufuji. Automatic music mixing with deep learning and out-of-domain data. In ISMIR. 2022.">MartinezRamirezLF+22</a>, <a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>. Thus, when the stimulus has the potential to outperform the reference or hidden anchor, the MUSHRA methodology is not recommended <span id="id5">[<a class="reference internal" href="../part_5/03_references.html#id129" title="Rec ITU-R. ITU-R BS. 1534-3, method for the subjective assessment of intermediate quality level of audio systems. International Telecommunications Union, Geneva, 2015.">IR15</a>]</span>.
Furthermore, we often test mixes for overall production quality or technical preference and not for their similarity to a reference mix, hence rendering the use of a hidden anchor reference as unnecessary.</p>
<p>Regarding the use of low and mid anchors, when the participants are experts, the use of such anchors might have a negative impact on the test results. This is due to the critical listening skills of experts, whose discrimination of a low anchor, such as a monaural or random processed mix, is trivial. Thus, the presence of a low anchor will tend to compress the ratings of the other stimuli and could distract participants from focusing on the significant contrastive differences within the mixtures <span id="id6">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>. Another argument for not including the anchor is to reduce the number of stimuli and thus allowing tests with a larger number of mixtures to be tested. It should be noted that when the participants are not exclusively experts, the use of low and mid anchors can serve its beneficial original purpose within the test.</p>
<p>Finally, the MUSHRA method recommends using stimuli of no more than 12 seconds, which, based on empirical data, we have found that experts consider this duration to be too short to adequately assess quality within a set of mixtures.</p>
<p>In general, it is not recommended to fully follow the MUSHRA methodology for the evaluation of this task, however, this multi-stimulus methodology could be further modified to fit the specific needs for the evaluation of automatic mixing systems.</p>
<figure class="align-center" id="webmushra">
<a class="reference internal image-reference" href="../_images/webmushra.svg"><img alt="../_images/webmushra.svg" src="../_images/webmushra.svg" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 27 </span><span class="caption-text">MUSHRA test implemented with webMUSHRA <span id="id7">[<a class="reference internal" href="../part_5/03_references.html#id112" title="Michael Schoeffler, Sarah Bartoschek, Fabian-Robert Stöter, Marlene Roess, Susanne Westphal, Bernd Edler, and Jürgen Herre. Webmushra—a comprehensive framework for web-based listening tests. Journal of Open Research Software, 2018.">SBStoter+18</a>]</span>.</span><a class="headerlink" href="#webmushra" title="Link to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="go-listen">
<a class="reference internal image-reference" href="../_images/go-listen.svg"><img alt="../_images/go-listen.svg" src="../_images/go-listen.svg" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 28 </span><span class="caption-text">MUSHRA test implemented with goListen <span id="id8">[<a class="reference internal" href="../part_5/03_references.html#id133" title="Dan Barry, Qijian Zhang, Pheobe Wenyi Sun, and Andrew Hines. Go listen: an end-to-end online listening test platform. Journal of Open Research Software, 2021.">BZSH21b</a>]</span>.</span><a class="headerlink" href="#go-listen" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="ape">
<h3>APE<a class="headerlink" href="#ape" title="Link to this heading">#</a></h3>
<p>As an alternative for multi-stimulus testing the Audio Perceptual Evaluation (APE) was proposed by <span id="id9">[<a class="reference internal" href="../part_5/03_references.html#id141" title="Brecht De Man and Joshua D Reiss. APE: audio perceptual evaluation toolbox for MATLAB. In Audio Engineering Society Convention 136. 2014.">DMR14</a>]</span>.
The main difference with the MUSHRA method is that all the stimuli are placed under the same continuous horizontal line, thus allowing instant visualization of the ratings. Also, the use of reference and anchor is optional as well as the maximum length of the stimuli.
Examples of APE testing interface used in recent automatic music mixing systems:</p>
<figure class="align-center" id="ape-dmc">
<a class="reference internal image-reference" href="../_images/APE_DMC.svg"><img alt="../_images/APE_DMC.svg" src="../_images/APE_DMC.svg" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29 </span><span class="caption-text">APE test from <span id="id10">[<a class="reference internal" href="../part_5/03_references.html#id139" title="Christian J. Steinmetz, Jordi Pons, Santiago Pascual, and Joan Serrà. Automatic multitrack mixing with a differentiable mixing console of neural audio effects. In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP). 2021.">SPPS21</a>]</span>.</span><a class="headerlink" href="#ape-dmc" title="Link to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="ape-wun-drums">
<a class="reference internal image-reference" href="../_images/APE_WaveUNet_Drums.svg"><img alt="../_images/APE_WaveUNet_Drums.svg" src="../_images/APE_WaveUNet_Drums.svg" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 30 </span><span class="caption-text">APE test from {cite}`martinez2021deep.</span><a class="headerlink" href="#ape-wun-drums" title="Link to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="ape-fxnorm">
<a class="reference internal image-reference" href="../_images/APE_FxNorm.svg"><img alt="../_images/APE_FxNorm.svg" src="../_images/APE_FxNorm.svg" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 31 </span><span class="caption-text">APE test from~\cite{martinez2022automatic}. For this test, dry stems were used as references. This is based on feedback from pilot tests and was proposed by the expert participants.</span><a class="headerlink" href="#ape-fxnorm" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="criteria">
<h2>Criteria<a class="headerlink" href="#criteria" title="Link to this heading">#</a></h2>
<p>The most common criterion used in multi-stimulus testing is to ask participants to rate various mixes according to their overall preference. This encompasses both technical and subjective criteria and is often based on a scale from 0 to 1 or from 0 to 100, with or without the use of semantic labels associated with a certain range of the numerical scale <span id="id11">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>.</p>
<p>When looking for more detailed and discriminatory perceptual ratings, the general preference criterion can be divided into Production Value, Clarity and Excitement as shown in <span id="id12">[<a class="reference internal" href="../part_5/03_references.html#id75" title="Marco A Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Stefan Uhlich, Chihiro Nagashima, and Yuki Mitsufuji. Automatic music mixing with deep learning and out-of-domain data. In ISMIR. 2022.">MartinezRamirezLF+22</a>, <a class="reference internal" href="../part_5/03_references.html#id29" title="Pedro D Pestana and Joshua D Reiss. A cross-adaptive dynamic spectral panning technique. In DAFx, 303–307. Erlangen, 2014.">PR14</a>]</span>, which are defined as follows:</p>
<ul class="simple">
<li><p><strong>Production Value</strong>: Technical quality of the mix. This corresponds to subjective preferences related to the overall technical quality of the mix, considering all the audio mixing characteristics; such as dynamics, EQ, balance, and stereo image.</p></li>
<li><p><strong>Clarity</strong>: Ability to differentiate musical sources. This is entirely objective and corresponds to the perceived presence or absence of masking.</p></li>
<li><p><strong>Excitement</strong> A non-technical subjective reaction to the mix. This is not related to an evaluation of quality, but to a more personal perception of novelty. Due to engaging, intriguing or thought-provoking aspects within the mix.</p></li>
</ul>
<p>It is worth noting that while the Clarity criterion measures the presence or absence of masking, this criterion is not objectively universal, and for certain genres or submixes, masking might be aesthetically desirable. However, Clarity can serve as an indicator for objective perceptual performance within mixes.</p>
</section>
<section id="advice">
<h2>Advice<a class="headerlink" href="#advice" title="Link to this heading">#</a></h2>
<p>The following are a set of general rules of thumb design decisions, and although they are not exhaustive, they can serve as a fundamental starting point when designing listening tests for automatic music mixing systems.</p>
<ul class="simple">
<li><p>Participants should be blind to the stimulus as much as possible, thus, participants must not be informed of the underlying methods to generate the mixes. The contrary could lead to a negative bias towards fully automated generated mixes.</p></li>
<li><p>Randomize the order of the stimuli and mixtures to be tested.</p></li>
<li><p>Results when participants have experience in mix engineering are more reliable.</p></li>
<li><p>Conduct a pilot listening test to get a clear idea of the approximate total duration and to recognize potential misunderstanding issues.</p></li>
<li><p>Always write detailed instructions and, if possible, also provide verbal instructions to the participants to minimize the risk of misunderstandings within the task.</p></li>
<li><p>Consider excluding participants if their total testing time is too short or if there are large deviations when compared to the other participants. However, when this occurs, please do report the exclusion of such participants.</p></li>
<li><p>Collect additional data, such as age, gender identity, years of mixing experience, and comments regarding the test. This could lead to additional insights and findings from the test.</p></li>
<li><p>The maximum total duration of a listening test in which listening fatigue does not affect the reliability of the results is 90 minutes {cite}`schatz2012impact}. However, such findings included a 10-minute break. Therefore, a recommendation is to keep the duration of the listening test under 45 minutes.</p></li>
<li><p>A training stage preceding the test may be beneficial to participants. This stage must be taken into account within the total duration of the test.</p></li>
<li><p>To assess various audio effects or mixing characteristics of mixes, experts prefer segments between 25 and 60 seconds. Typically, such a segment should cover a verse and a chorus or at least the transition between said musical parts.</p></li>
<li><p>Do not use a ground truth reference unless the specific task at hand deems it necessary.</p></li>
<li><p>Low and mid anchors tend not to be necessary if participants are skilled or experienced in mix engineering.</p></li>
<li><p>The number of stimuli per multi-stimulus test page must be less than 12 <span id="id13">[<a class="reference internal" href="../part_5/03_references.html#id10" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span>.</p></li>
<li><p>If labels are assigned to the rating scale, they must be properly defined and explained to the participants. Examples of such labels can be “Bad, Poor, Fair, Good, Excellent”.</p></li>
<li><p>Participants prefer synchronized playback between stimuli so they can better focus on contrast differences between mixes.</p></li>
<li><p>Loudness should not influence the rated criteria. Therefore, samples must be loudness normalized, except for the cases where loudness is crucial to the criteria to be rated.</p></li>
<li><p>Participants must limit the times they adjust the volume of their listening settings. Ideally this should be done once and only at the beginning of the test. These instructions must be given to the participants.</p></li>
</ul>
</section>
<section id="platforms">
<h2>Platforms<a class="headerlink" href="#platforms" title="Link to this heading">#</a></h2>
<p>The following are the most common used platforms for perceptual listening tests:</p>
<section id="web-audio-evaluation-tool">
<h3>Web Audio Evaluation Tool<a class="headerlink" href="#web-audio-evaluation-tool" title="Link to this heading">#</a></h3>
<p><span id="id14">[<a class="reference internal" href="../part_5/03_references.html#id113">JMM+15</a>]</span></p>
<ul class="simple">
<li><p>APE and MUSHRA</p></li>
<li><p>Reference is optional</p></li>
<li><p>Training stage is possible</p></li>
<li><p>Loudness normalization within the platform</p></li>
<li><p>Synchronized playback</p></li>
<li><p>Customization requires effort</p></li>
</ul>
</section>
<section id="id15">
<h3>webMUSHRA<a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<p><span id="id16">[<a class="reference internal" href="../part_5/03_references.html#id112" title="Michael Schoeffler, Sarah Bartoschek, Fabian-Robert Stöter, Marlene Roess, Susanne Westphal, Bernd Edler, and Jürgen Herre. Webmushra—a comprehensive framework for web-based listening tests. Journal of Open Research Software, 2018.">SBStoter+18</a>]</span></p>
<ul class="simple">
<li><p>MUSHRA</p></li>
<li><p>Training stage is possible</p></li>
<li><p>Fade-in/out within the platform</p></li>
<li><p>Synchronized playback</p></li>
<li><p>Customization requires effort</p></li>
</ul>
</section>
<section id="golisten">
<h3>goListen<a class="headerlink" href="#golisten" title="Link to this heading">#</a></h3>
<p><span id="id17">[<a class="reference internal" href="../part_5/03_references.html#id111" title="Dan Barry, Qijian Zhang, Pheobe Wenyi Sun, and Andrew Hines. Go listen: an end-to-end online listening test platform. Journal of Open Research Software, 2021. URL: http://doi.org/10.5334/jors.361.">BZSH21a</a>]</span></p>
<ul class="simple">
<li><p>MUSHRA</p></li>
<li><p>Reference is optional</p></li>
<li><p>Synchronized playback</p></li>
<li><p>Customization requires effort</p></li>
<li><p>Ease-of-use and implementation</p></li>
</ul>
</section>
</section>
<section id="challenges">
<h2>Challenges<a class="headerlink" href="#challenges" title="Link to this heading">#</a></h2>
<p>It is worth noting that another limitation of the objective and subjective evaluation methods discussed above is the inability to measure whether the generated mixes have long-temporal coherence. This is because a song’s mixing style is usually consistent throughout the song’s length—and often throughout the entire album or EP—so we should investigate whether automatic mixing systems produce mixes with this level of coherence, which means that methods to measure this long-temporal coherence must be researched. For example, evaluation systems that measure mixing style coherence within different song elements such as verses, choruses, and so on, could yield more accurate objective and subjective ways of evaluating generated mixes.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./part_4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="01_evaluation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Evaluation</p>
      </div>
    </a>
    <a class="right-next"
       href="03_evaluate.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Evaluation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#participants">Participants</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-tests">Types of Tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mushra">MUSHRA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ape">APE</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#criteria">Criteria</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advice">Advice</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#platforms">Platforms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#web-audio-evaluation-tool">Web Audio Evaluation Tool</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">webMUSHRA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#golisten">goListen</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges">Challenges</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Christian J. Steinmetz, Soumya Sai Vanka, Marco Martínez, Gary Bromham
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>