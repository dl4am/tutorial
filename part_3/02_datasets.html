
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Datasets for automix systems &#8212; Deep Learning for Automatic Mixing</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'part_3/02_datasets';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Models" href="03_models.html" />
    <link rel="prev" title="Inference" href="01_inference.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../landing-page.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Deep Learning for Automatic Mixing - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Deep Learning for Automatic Mixing - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../landing-page.html">
                    Deep Learning for Automatic Mixing 
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Audio Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part_1/01_music-production.html">Music Production</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../part_1/02_audio-effects.html">Audio effects</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../part_1/audio-effects/01_panning.html">Panning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_1/audio-effects/02_equalization.html">Equalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_1/audio-effects/03_compression.html">Compression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_1/audio-effects/04_reverberation.html">Reverberation</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Automatic Mixing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part_2/01_imp.html">Intelligent Music Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_2/02_problem.html">Problem Formulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_2/03_diffsp.html">Differentiable signal processing</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../part_2/04_methods.html">Methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../part_2/methods/01_mixwaveunet.html">Mix-Wave-U-Net</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_2/methods/02_dmc.html">Differentiable Mixing Console</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part_2/methods/03_diffmst.html">Differentable Mixing Style transfer</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../part_2/05_loss-functions.html">Loss Functions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Implementation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_inference.html">Inference</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Datasets for automix systems</a></li>


<li class="toctree-l1"><a class="reference internal" href="03_models.html">Models</a></li>


<li class="toctree-l1"><a class="reference internal" href="04_training.html">Training</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Evaluation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part_4/01_evaluation.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_4/02_listening-tests.html">Listening Tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_4/03_evaluate.html">Evaluation</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Conclusion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part_5/01_future-directions.html">Future Directions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_5/02_conclusion.html">Conclusions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part_5/03_references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/dl4am/tutorial/blob/main/book/part_3/02_datasets.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/dl4am/tutorial" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/dl4am/tutorial/issues/new?title=Issue%20on%20page%20%2Fpart_3/02_datasets.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/part_3/02_datasets.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Datasets for automix systems</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Datasets for automix systems</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#listed-below-are-few-of-the-advised-variables-that-you-should-define-in-the-dataset-class-definition">Listed below are few of the advised variables that you should define in the dataset class definition:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-processing-advice-for-loading-multitrack-data">Pre-processing advice for loading multitrack data:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enst-drums">ENST Drums</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dsd100-dataset">DSD100 dataset</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#medleydb-dataset">MedleyDB Dataset</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-dataset">Load the dataset.</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="datasets-for-automix-systems">
<h1>Datasets for automix systems<a class="headerlink" href="#datasets-for-automix-systems" title="Link to this heading">#</a></h1>
<p>In this notebook, we will first discuss the datasets used to train the automix systems. Thereafter, we will see how to pre-process the data and set up the dataloaders for training the deep learning models for these systems.</p>
<p>Training automix models requires paired multitrack stems and their corresponding mixdowns. Below listed are the desired properties for these datasets:</p>
<ol class="arabic simple">
<li><p><strong>Time alligned stems and mixes</strong> : We require time-alligned stems and mixes to allow the models to learn timewise transformation relationships.</p></li>
<li><p><strong>Diverse instrument categories</strong> : The more diverse the number of instruments in the dataset, the more likely is the trained system to perform well with real-world songs.</p></li>
<li><p><strong>Diverse genres of songs</strong> : The mixing practices vary slightly from one genre to another. Hence, if the dataset has multitrack mixes from different genres, the trained system will be exposed to more diverse distribution of data.</p></li>
<li><p><strong>Dry multitrack stems</strong> : Mixing involves processing the recorded dry stems for corrective and aesthetic reasons before summing them to form a cohesive mixture. For a model to learn the correct way to process the stems to generate mixes, we need to train it on dry unprocessed stems and mix pairs. However, more recently approaches to use processed stems from datasets like MUSEDB to train automix systems have been explored. These approaches use a pre-processing effect normalisation method to deal with pre-processed wet stems. For the scope of this tutorial, we do not discuss these methods. However, we recommend having a look at <a class="reference external" href="https://arxiv.org/abs/2208.11428">this</a> paper being presented at ISMIR 2022.</p></li>
</ol>
<p>Here we list the datasets available for training automix systems.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Dataset</p></th>
<th class="head"><p>Size(Hrs)</p></th>
<th class="head"><p>no. of Songs</p></th>
<th class="head"><p>no. of Instrument Category</p></th>
<th class="head"><p>no. of tracks</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Usage Permissions</p></th>
<th class="head"><p>Other info</p></th>
<th class="head"><p>Remarks</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://medleydb.weebly.com/">MedleyDB</a></p></td>
<td><p>7.2</p></td>
<td><p>122</p></td>
<td><p>82</p></td>
<td><p>1-26</p></td>
<td><p>Multitrack, Wav</p></td>
<td><p>Open</p></td>
<td><p>44.1KHz, 16 bit, stereo</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://perso.telecom-paristech.fr/grichard/ENST-drums/">ENST Drums</a></p></td>
<td><p>1.25</p></td>
<td><p>-</p></td>
<td><p>1</p></td>
<td><p>8</p></td>
<td><p>Drums, Wav/AVI</p></td>
<td><p>Limited</p></td>
<td><p>44.1KHz, 16 bit, stereo</p></td>
<td><p>Drums only dataset</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://www.cambridge-mt.com/ms/mtk/">Cambridge Multitrack</a></p></td>
<td><p>&gt;3</p></td>
<td><p>&gt;50</p></td>
<td><p>&gt;5</p></td>
<td><p>5-70</p></td>
<td><p>Multitrack, Wav</p></td>
<td><p>open</p></td>
<td><p>44.1KHz, 16/24 bit, Stereo</p></td>
<td><p>Not time alligned, recordings for all the songs are not uniform</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://sigsep.github.io/datasets/musdb.html">MUSEDB</a></p></td>
<td><p>~10</p></td>
<td><p>150</p></td>
<td><p>4</p></td>
<td><p>4</p></td>
<td><p>Multitrack, Wav</p></td>
<td><p>open</p></td>
<td><p>44.1KHz, Stereo</p></td>
<td><p>used mainly for source separation, wet stems</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="http://www.slakh.com/">Slakh</a></p></td>
<td><p>145</p></td>
<td><p>2100</p></td>
<td><p>34</p></td>
<td><p>4-48</p></td>
<td><p>Synthesised, Flac,</p></td>
<td><p>open</p></td>
<td><p>44.1KHz, 16 bit, stereo</p></td>
<td><p>used mainly for source separation; sometimes wet stems</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://weathervanemusic.org/shakingthrough/episode-index">Shaking Through</a></p></td>
<td><p>4.5</p></td>
<td><p>68</p></td>
<td><p>&gt;30</p></td>
<td><p>&gt;40</p></td>
<td><p>Multitrack, Wav</p></td>
<td><p>User only</p></td>
<td><p>44.1/88.2KHz, 16/24 bit, stereo</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://bitmidi.com/">BitMIDI</a></p></td>
<td><p>-</p></td>
<td><p>&gt;1M</p></td>
<td><p>&gt;5</p></td>
<td><p>&gt;5</p></td>
<td><p>Multitrack MIDI</p></td>
<td><p>open</p></td>
<td><p>MIDI data</p></td>
<td><p>MIDI data submitted by users across world</p></td>
</tr>
</tbody>
</table>
</div>
<p>For this tutorial, we will use ENST-drums for training Wave-U-Net and ENST-drums, DSD100, and MedleyDB for training Differentiable Mixing Console(DMC).</p>
<p>In the following section, we will discuss the recommended pre-processing methods for these datasets and the methods to set up dataloaders for training the models. This notebook assumes that you have already installed the <code class="docutils literal notranslate"><span class="pre">automix</span></code> package.</p>
<p>We define dataset classes for DSD100, MedleyDB, and ENSTdrums, and then use <code class="docutils literal notranslate"><span class="pre">getitem()</span></code> function to load the audio data into the dataloader for training and testing.</p>
<section id="listed-below-are-few-of-the-advised-variables-that-you-should-define-in-the-dataset-class-definition">
<h2>Listed below are few of the advised variables that you should define in the dataset class definition:<a class="headerlink" href="#listed-below-are-few-of-the-advised-variables-that-you-should-define-in-the-dataset-class-definition" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Root directory</strong> of the folder containing the dataset.</p></li>
<li><p><strong>Length of the audio</strong> you wish to load for training/testing.</p></li>
<li><p><strong>Sample rate</strong> at which you wish to load the audio data.</p></li>
</ol>
</section>
<section id="pre-processing-advice-for-loading-multitrack-data">
<h2>Pre-processing advice for loading multitrack data:<a class="headerlink" href="#pre-processing-advice-for-loading-multitrack-data" title="Link to this heading">#</a></h2>
<ol class="arabic">
<li><p>Discard the examples from the dataset that have length shorter than the prescribed length.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> ```
 #code from automix/data/drums.py
 #remove any mixes that are shorter than the requested length
 self.mix_filepaths = [
     fp
     for fp in self.mix_filepaths
     
     # use torchaudio.info to get information about the audio. This is much faster than loading the whole audio.
     if torchaudio.info(fp).num_frames &gt; self.length
 ]
 ```
</pre></div>
</div>
</li>
<li><p>Loudness normalise the stems and the mixes after loading.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> ```
 #code from automix/data/drums.py
 y /= y.abs().max().clamp(1e-8) 
 ```
</pre></div>
</div>
</li>
<li><p>Look out for silence in the loaded audio: Common practice is to generate a random starting index for the frame from which the audio is loaded. However, it is likely that some of the multitrack stem or the mix as a whole could have just silence in this chunk of loaded audio. This results in generation of NaN in the audio tensor when it is normalised. In the below shown code block, we show how to check for silence. We keep generating a new starting index(<code class="docutils literal notranslate"><span class="pre">offset</span></code>)) for loading the audio until the audio has some content and is not just silence(<code class="docutils literal notranslate"><span class="pre">silent</span> <span class="pre">is</span> <span class="pre">False</span></code>).</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>         ```
         #code from automix/data/drums.py
         # load the chunk of the mix
                 silent = True
                 while silent:
                 # get random offset
                 offset = np.random.randint(0, md.num_frames - self.length - 1)

                 y, sr = torchaudio.load(
                         mix_filepath,
                         frame_offset=offset,
                         num_frames=self.length,
                 )
                 energy = (y**2).mean()
                 if energy &gt; 1e-8:
                         silent = False

                 # only normalise the audio that are not silent
                 y /= y.abs().max().clamp(1e-8)  # peak normalize
         ```
</pre></div>
</div>
</li>
</ol>
</section>
<section id="enst-drums">
<h2>ENST Drums<a class="headerlink" href="#enst-drums" title="Link to this heading">#</a></h2>
<p>Below described is the folder structure of the ENST Drums dataset:</p>
<ul class="simple">
<li><p>ENST-Drums</p>
<ul>
<li><p>drummer_1</p>
<ul>
<li><p>annotation</p></li>
<li><p>audio</p>
<ul>
<li><p>accompaniment</p></li>
<li><p>dry mix</p></li>
<li><p>hi-hat</p></li>
<li><p>kick</p></li>
<li><p>overhead L</p></li>
<li><p>overhead R</p></li>
<li><p>snare</p></li>
<li><p>tom 1</p></li>
<li><p>tom 2</p></li>
<li><p>wet mix</p></li>
</ul>
</li>
</ul>
</li>
<li><p>drummer_2</p>
<ul>
<li><p>(same structure as drummer_1)</p></li>
</ul>
</li>
<li><p>drummer_3</p>
<ul>
<li><p>(same structure as drummer_1)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>We are going to use audios from the wet mix folder for this tutorial.</p>
<p>In the automix/data/drums, we define an ENSTDrumsdataset class and use the <code class="docutils literal notranslate"><span class="pre">getitem()</span></code> to load data for the dataloader in our training loop.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ENSTDrumsDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">root_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">drummers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="n">track_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;kick&quot;</span><span class="p">,</span>
            <span class="s2">&quot;snare&quot;</span><span class="p">,</span>
            <span class="s2">&quot;hi-hat&quot;</span><span class="p">,</span>
            <span class="s2">&quot;overhead_L&quot;</span><span class="p">,</span>
            <span class="s2">&quot;overhead_R&quot;</span><span class="p">,</span>
            <span class="s2">&quot;tom_1&quot;</span><span class="p">,</span>
            <span class="s2">&quot;tom_2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;tom_3&quot;</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">wet_mix</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">hits</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_examples_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</pre></div>
</div>
<ul class="simple">
<li><p>We use indices to define the train-test split.</p></li>
</ul>
<ul>
<li><p>In the <code class="docutils literal notranslate"><span class="pre">getitem()</span></code> of the dataset class, we first generate a <code class="docutils literal notranslate"><span class="pre">mix_idx</span></code> which is a random number in the range of 0 and the number of songs in the directory(len of mix_filepaths). This allows to randomly pick a mix/song from the mix_filepath.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
        <span class="c1"># select a mix at random</span>
        <span class="n">mix_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mix_filepaths</span><span class="p">))</span>
        <span class="n">mix_filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mix_filepaths</span><span class="p">[</span><span class="n">mix_idx</span><span class="p">]</span>
        <span class="n">example_id</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">mix_filepath</span><span class="p">)</span>
        <span class="n">drummer_id</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="n">mix_filepath</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">sep</span><span class="p">)[</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>

        <span class="n">md</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">mix_filepath</span><span class="p">)</span>  <span class="c1"># check length</span>
</pre></div>
</div>
</li>
<li><p>Next, we load the mix(<code class="docutils literal notranslate"><span class="pre">y</span></code>) from the filepath. Make sure to check for silence as discussed above. Once the mix is loaded, peak normalise it.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>        <span class="c1"># load the chunk of the mix</span>
        <span class="n">silent</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">while</span> <span class="n">silent</span><span class="p">:</span>
            <span class="c1"># get random offset</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">md</span><span class="o">.</span><span class="n">num_frames</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
                <span class="n">mix_filepath</span><span class="p">,</span>
                <span class="n">frame_offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                <span class="n">num_frames</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">energy</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">energy</span> <span class="o">&gt;</span> <span class="mf">1e-8</span><span class="p">:</span>
                <span class="n">silent</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">y</span> <span class="o">/=</span> <span class="n">y</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">1e-8</span><span class="p">)</span>  <span class="c1"># peak normalize</span>
</pre></div>
</div>
</li>
<li><p>Last step is to load the stems. <code class="docutils literal notranslate"><span class="pre">max_num_tracks</span></code> is the maximum number of tracks you want to load. Some songs might have less or more stems than this number. We keep a track of empty stems using <code class="docutils literal notranslate"><span class="pre">pad</span></code> which is <code class="docutils literal notranslate"><span class="pre">True</span></code> whenever the stem is empty.
The <code class="docutils literal notranslate"><span class="pre">getitem()</span></code> returns stems tensor (<code class="docutils literal notranslate"><span class="pre">x</span></code>), mix (<code class="docutils literal notranslate"><span class="pre">y</span></code>), and <code class="docutils literal notranslate"><span class="pre">pad</span></code> information.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  # -------------------- load the tracks from disk --------------------
  x = torch.zeros((self.max_num_tracks, self.length))
  pad = [True] * self.max_num_tracks  # note which tracks are empty

  for tidx, track_name in enumerate(self.track_names):
      track_filepath = os.path.join(
          self.root_dir,
          drummer_id,
          &quot;audio&quot;,
          track_name,
          example_id,
      )
      if os.path.isfile(track_filepath):
          x_s, sr = torchaudio.load(
              track_filepath,
              frame_offset=offset,
              num_frames=self.length,
          )
          x_s /= x_s.abs().max().clamp(1e-6)
          x_s *= 10 ** (-12 / 20.0)
          x[tidx, :] = x_s
          pad[tidx] = False

  return x, y, pad
</pre></div>
</div>
</li>
</ul>
</section>
<section id="dsd100-dataset">
<h2>DSD100 dataset<a class="headerlink" href="#dsd100-dataset" title="Link to this heading">#</a></h2>
<p>Below described is the folder structure of the DSD100 dataset:</p>
<ul class="simple">
<li><p>ENST Drums</p>
<ul>
<li><p>Train</p>
<ul>
<li><p>Songdir(songname)</p>
<ul>
<li><p>vocals.wav</p></li>
<li><p>bass.wav</p></li>
<li><p>drums.wav</p></li>
<li><p>other.wav</p></li>
<li><p>accompaniment.wav</p></li>
<li><p>mixture.wav</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Test</p>
<ul>
<li><p>Songdir(songname)</p>
<ul>
<li><p>vocals.wav</p></li>
<li><p>bass.wav</p></li>
<li><p>drums.wav</p></li>
<li><p>other.wav</p></li>
<li><p>accompaniment.wav</p></li>
<li><p>mixture.wav</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Note: Accompaniment is the sum of bass, drums, and other.</p>
<p>For the purpose of training our models, we use:</p>
<p><strong>Input</strong>: vocals, bass, drums, and other</p>
<p><strong>Output</strong>: Mixture</p>
<p>We will first define a dataset class and use the <code class="docutils literal notranslate"><span class="pre">getitem()</span></code> function to load items into the dataloader.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Code from automix/data/dsd100.py</span>

<span class="k">class</span> <span class="nc">DSD100Dataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">root_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">track_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;bass&quot;</span><span class="p">,</span> <span class="s2">&quot;drums&quot;</span><span class="p">,</span> <span class="s2">&quot;other&quot;</span><span class="p">,</span> <span class="s2">&quot;vocals&quot;</span><span class="p">],</span>
        <span class="n">num_examples_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</pre></div>
</div>
<p>Hereafter, we follow similar structure in <code class="docutils literal notranslate"><span class="pre">getitem()</span></code> as in the case of ENSTDrums.</p>
<ul class="simple">
<li><p>We first pick a mix_filepath on random and then look for non-silent part to load the mix(<code class="docutils literal notranslate"><span class="pre">y</span></code>).</p></li>
<li><p>Then, we load stems(<code class="docutils literal notranslate"><span class="pre">x</span></code>) starting with the same start_idx of the prescribed length.</p></li>
<li><p>We peak normalise all the loaded stems and mix and save the empty stem inofrmation in the <code class="docutils literal notranslate"><span class="pre">pad</span></code> variable.</p></li>
<li><p>We then return <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, and <code class="docutils literal notranslate"><span class="pre">pad</span></code>.</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="medleydb-dataset">
<h1>MedleyDB Dataset<a class="headerlink" href="#medleydb-dataset" title="Link to this heading">#</a></h1>
<p>Described below is the folder structure for MedleyDB:</p>
<ul class="simple">
<li><p>MedleyDB</p>
<ul>
<li><p>songnames</p>
<ul>
<li><p>songname_MIX.wav</p></li>
<li><p>songname_STEMS</p>
<ul>
<li><p>songname_STEMS_{stem_number}.wav</p></li>
</ul>
</li>
<li><p>songname_RAW</p>
<ul>
<li><p>songname_STEMS_{stem_number}_{track_number}.wav</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>STEMS folder have some of the RAW audio tracks combined into a single audio file.</p></li>
<li><p>RAW folder contains all of the audio tracks individually.</p></li>
</ul>
<p>We define the corresponding dataset class like before.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MedleyDBDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">root_dirs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="n">max_num_tracks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">num_examples_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">buffer_size_gb</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">3.0</span><span class="p">,</span>
        <span class="n">buffer_reload_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
        <span class="n">normalization</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;peak&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">indices</span></code> define the train-test split.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">buffer_size_gb</span></code> specifies the amount of data loaded onto RAM</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">buffer_reload_rate</span></code> specifies the rate of loading new data onto the RAM.</p></li>
</ul>
<p>In case of large datasets like MedleyDB which have large number of stems in the songs, it could be very time-consuming to always load audio tracks from the disk. However, we could load a small subset of the dataset randomly onto the RAM every few iterations to speed up the process.</p>
<p>We load <code class="docutils literal notranslate"><span class="pre">nbytes_loaded</span></code> amount of data onto the RAM everytime the <code class="docutils literal notranslate"><span class="pre">items_since_load</span></code> &gt; <code class="docutils literal notranslate"><span class="pre">buffer_reload_rate</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#code from automix/data/medleydb.py</span>

<span class="k">def</span> <span class="nf">reload_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">examples</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># clear buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">items_since_load</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># reset iteration counter</span>
        <span class="n">nbytes_loaded</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># counter for data in RAM</span>

        <span class="c1"># different subset in each</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mix_dirs</span><span class="p">)</span>

        <span class="c1"># load files into RAM</span>
        <span class="k">for</span> <span class="n">mix_dir</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mix_dirs</span><span class="p">:</span>
            <span class="n">mix_id</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">mix_dir</span><span class="p">)</span>
            <span class="n">mix_filepath</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mix_dir</span><span class="p">,</span> <span class="s2">&quot;*.wav&quot;</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># now check the length of the mix</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">mix_filepath</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Skipping </span><span class="si">{</span><span class="n">mix_filepath</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="n">mix_num_frames</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">nbytes</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">element_size</span><span class="p">()</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
            <span class="n">nbytes_loaded</span> <span class="o">+=</span> <span class="n">nbytes</span>

            <span class="c1"># now find all the track filepaths</span>
            <span class="n">track_filepaths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mix_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mix_id</span><span class="si">}</span><span class="s2">_RAW&quot;</span><span class="p">,</span> <span class="s2">&quot;*.wav&quot;</span><span class="p">))</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">track_filepaths</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_num_tracks</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># check length of each track</span>
            <span class="n">tracks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">tidx</span><span class="p">,</span> <span class="n">track_filepath</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">track_filepaths</span><span class="p">):</span>
                <span class="n">x</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">track_filepath</span><span class="p">)</span>
                <span class="n">tracks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

                <span class="n">nbytes</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">element_size</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
                <span class="n">nbytes_loaded</span> <span class="o">+=</span> <span class="n">nbytes</span>

                <span class="n">track_num_frames</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">track_num_frames</span> <span class="o">&lt;</span> <span class="n">mix_num_frames</span><span class="p">:</span>
                    <span class="n">mix_num_frames</span> <span class="o">=</span> <span class="n">track_num_frames</span>

            <span class="c1"># store this example</span>
            <span class="n">example</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;mix_id&quot;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">mix_filepath</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">sep</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="s2">&quot;mix_filepath&quot;</span><span class="p">:</span> <span class="n">mix_filepath</span><span class="p">,</span>
                <span class="s2">&quot;mix_audio&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
                <span class="s2">&quot;num_frames&quot;</span><span class="p">:</span> <span class="n">mix_num_frames</span><span class="p">,</span>
                <span class="s2">&quot;track_filepaths&quot;</span><span class="p">:</span> <span class="n">track_filepaths</span><span class="p">,</span>
                <span class="s2">&quot;track_audio&quot;</span><span class="p">:</span> <span class="n">tracks</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>

            <span class="c1"># check the size of loaded data</span>
            <span class="k">if</span> <span class="n">nbytes_loaded</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size_gb</span> <span class="o">*</span> <span class="mf">1e9</span><span class="p">:</span>
                <span class="k">break</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/csteinmetz1/automix-toolkit
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting git+https://github.com/csteinmetz1/automix-toolkit
  Cloning https://github.com/csteinmetz1/automix-toolkit to /tmp/pip-req-build-ynp21f13
  Running command git clone -q https://github.com/csteinmetz1/automix-toolkit /tmp/pip-req-build-ynp21f13
Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (1.12.1+cu113)
Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (0.13.1+cu113)
Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (0.12.1+cu113)
Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (1.8.3.post1)
Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (4.64.1)
Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (1.21.6)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (3.2.2)
Requirement already satisfied: pedalboard in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (0.6.6)
Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (1.7.3)
Requirement already satisfied: auraloss in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (0.2.2)
Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (3.2)
Requirement already satisfied: pyloudnorm in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (0.1.0)
Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (from automix-toolkit==0.0.1) (0.0.post1)
Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (from auraloss-&gt;automix-toolkit==0.0.1) (0.8.1)
Requirement already satisfied: resampy&gt;=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (0.4.2)
Requirement already satisfied: decorator&gt;=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (4.4.2)
Requirement already satisfied: scikit-learn!=0.19.0,&gt;=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (1.0.2)
Requirement already satisfied: pooch&gt;=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (1.6.0)
Requirement already satisfied: numba&gt;=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (0.56.4)
Requirement already satisfied: soundfile&gt;=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (0.11.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (21.3)
Requirement already satisfied: audioread&gt;=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (3.0.0)
Requirement already satisfied: joblib&gt;=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (1.2.0)
Requirement already satisfied: llvmlite&lt;0.40,&gt;=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba&gt;=0.43.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (0.39.1)
Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba&gt;=0.43.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (57.4.0)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba&gt;=0.43.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (4.13.0)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging&gt;=20.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (3.0.9)
Requirement already satisfied: appdirs&gt;=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch&gt;=1.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (1.4.4)
Requirement already satisfied: requests&gt;=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch&gt;=1.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (2.23.0)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (3.0.4)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (2.10)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (2022.9.24)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (1.24.3)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,&gt;=0.14.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (3.1.0)
Requirement already satisfied: cffi&gt;=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile&gt;=0.10.2-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (1.15.1)
Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi&gt;=1.0-&gt;soundfile&gt;=0.10.2-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (2.21)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata-&gt;numba&gt;=0.43.0-&gt;librosa-&gt;auraloss-&gt;automix-toolkit==0.0.1) (3.10.0)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;automix-toolkit==0.0.1) (0.11.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;automix-toolkit==0.0.1) (2.8.2)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;automix-toolkit==0.0.1) (1.4.4)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;automix-toolkit==0.0.1) (1.15.0)
Requirement already satisfied: future&gt;=0.16.0 in /usr/local/lib/python3.8/dist-packages (from pyloudnorm-&gt;automix-toolkit==0.0.1) (0.16.0)
Requirement already satisfied: torchmetrics&gt;=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning-&gt;automix-toolkit==0.0.1) (0.11.0)
Requirement already satisfied: tensorboardX&gt;=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning-&gt;automix-toolkit==0.0.1) (2.5.1)
Requirement already satisfied: PyYAML&gt;=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning-&gt;automix-toolkit==0.0.1) (6.0)
Requirement already satisfied: typing-extensions&gt;=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning-&gt;automix-toolkit==0.0.1) (4.1.1)
Requirement already satisfied: lightning-utilities==0.3.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning-&gt;automix-toolkit==0.0.1) (0.3.0)
Requirement already satisfied: fsspec[http]&gt;2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning-&gt;automix-toolkit==0.0.1) (2022.11.0)
Requirement already satisfied: fire in /usr/local/lib/python3.8/dist-packages (from lightning-utilities==0.3.*-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (0.4.0)
Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]&gt;2021.06.0-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (3.8.3)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (4.0.2)
Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (2.1.1)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (22.1.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (1.3.3)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (1.3.1)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (1.8.1)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&gt;2021.06.0-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (6.0.2)
Requirement already satisfied: protobuf&lt;=3.20.1,&gt;=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX&gt;=2.2-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (3.19.6)
Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire-&gt;lightning-utilities==0.3.*-&gt;pytorch_lightning-&gt;automix-toolkit==0.0.1) (2.1.1)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision-&gt;automix-toolkit==0.0.1) (7.1.2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">automix.data</span> <span class="kn">import</span> <span class="n">DSD100Dataset</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">librosa</span>
<span class="kn">import</span> <span class="nn">librosa.display</span>
<span class="kn">import</span> <span class="nn">IPython</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
</pre></div>
</div>
</div>
</div>
<p>Now we will download a subset of DSD100 and load it using the dataloader.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#First lets download a subset of DSD100</span>
<span class="o">!</span>wget<span class="w"> </span>https://huggingface.co/csteinmetz1/automix-toolkit/resolve/main/DSD100subset.zip
<span class="o">!</span>unzip<span class="w"> </span>-o<span class="w"> </span>DSD100subset.zip<span class="w"> </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--2022-12-04 03:54:36--  https://huggingface.co/csteinmetz1/automix-toolkit/resolve/main/DSD100subset.zip
Resolving huggingface.co (huggingface.co)... 3.234.187.147, 54.147.99.175, 2600:1f18:147f:e850:d78f:7d9d:6ec3:2aee, ...
Connecting to huggingface.co (huggingface.co)|3.234.187.147|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://cdn-lfs.huggingface.co/repos/ec/ee/ecee38df047e3f2db1bd8c31a742f3a08f557470cd67cb487402a9c3ed91b5ea/3544bf18ffbea78aee3273ba8267a6cb15aa04b52bc430e2f39755d40d212208?response-content-disposition=attachment%3B%20filename%3D%22DSD100subset.zip%22&amp;Expires=1670385277&amp;Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2VjL2VlL2VjZWUzOGRmMDQ3ZTNmMmRiMWJkOGMzMWE3NDJmM2EwOGY1NTc0NzBjZDY3Y2I0ODc0MDJhOWMzZWQ5MWI1ZWEvMzU0NGJmMThmZmJlYTc4YWVlMzI3M2JhODI2N2E2Y2IxNWFhMDRiNTJiYzQzMGUyZjM5NzU1ZDQwZDIxMjIwOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMkRTRDEwMHN1YnNldC56aXAlMjIiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NzAzODUyNzd9fX1dfQ__&amp;Signature=STySP8RVdnHfKtN3H2G4gCTGtufLX64ng8Hxbw6oqRnbvzEjvIIValONjHq4WUh0b1u7VqZXGCzRJGQBIp9ZZ6KdpajUD3DYEpcuseKBJA01ZkBZvUkO4WbfvSlfutZzYu30-FCCP0sF9aSms~Z6WpTEcooLiT53YyLyQktUY5ggM3ghDFupG8qlHjjR3D5FnMg3dDKQo-5blOtlF622NllOFYjPnuOY8KB3o5T0cIUUUDBW6lzi~MkhGjnZdib4wB~h8uv4ZfJPsPS6lE0LpphVm8zTDAX24t5yWLIBEcXZnhiSnd7C7WTdRV-sllQhoL4C96Dcr2RlQjDG72mS7g__&amp;Key-Pair-Id=KVTP0A1DKRTAX [following]
--2022-12-04 03:54:37--  https://cdn-lfs.huggingface.co/repos/ec/ee/ecee38df047e3f2db1bd8c31a742f3a08f557470cd67cb487402a9c3ed91b5ea/3544bf18ffbea78aee3273ba8267a6cb15aa04b52bc430e2f39755d40d212208?response-content-disposition=attachment%3B%20filename%3D%22DSD100subset.zip%22&amp;Expires=1670385277&amp;Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2VjL2VlL2VjZWUzOGRmMDQ3ZTNmMmRiMWJkOGMzMWE3NDJmM2EwOGY1NTc0NzBjZDY3Y2I0ODc0MDJhOWMzZWQ5MWI1ZWEvMzU0NGJmMThmZmJlYTc4YWVlMzI3M2JhODI2N2E2Y2IxNWFhMDRiNTJiYzQzMGUyZjM5NzU1ZDQwZDIxMjIwOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMkRTRDEwMHN1YnNldC56aXAlMjIiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NzAzODUyNzd9fX1dfQ__&amp;Signature=STySP8RVdnHfKtN3H2G4gCTGtufLX64ng8Hxbw6oqRnbvzEjvIIValONjHq4WUh0b1u7VqZXGCzRJGQBIp9ZZ6KdpajUD3DYEpcuseKBJA01ZkBZvUkO4WbfvSlfutZzYu30-FCCP0sF9aSms~Z6WpTEcooLiT53YyLyQktUY5ggM3ghDFupG8qlHjjR3D5FnMg3dDKQo-5blOtlF622NllOFYjPnuOY8KB3o5T0cIUUUDBW6lzi~MkhGjnZdib4wB~h8uv4ZfJPsPS6lE0LpphVm8zTDAX24t5yWLIBEcXZnhiSnd7C7WTdRV-sllQhoL4C96Dcr2RlQjDG72mS7g__&amp;Key-Pair-Id=KVTP0A1DKRTAX
Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.157.162.58, 108.157.162.95, 108.157.162.27, ...
Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.157.162.58|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 126074934 (120M) [application/zip]
Saving to: DSD100subset.zip.1

DSD100subset.zip.1  100%[===================&gt;] 120.23M  64.7MB/s    in 1.9s    

2022-12-04 03:54:39 (64.7 MB/s) - DSD100subset.zip.1 saved [126074934/126074934]

Archive:  DSD100subset.zip
  inflating: DSD100subset/dsd100.xlsx  
  inflating: DSD100subset/Sources/Dev/081 - Patrick Talbot - Set Me Free/drums.wav  
  inflating: DSD100subset/Sources/Dev/081 - Patrick Talbot - Set Me Free/other.wav  
  inflating: DSD100subset/Sources/Dev/081 - Patrick Talbot - Set Me Free/bass.wav  
  inflating: DSD100subset/Sources/Dev/081 - Patrick Talbot - Set Me Free/vocals.wav  
  inflating: DSD100subset/Sources/Dev/055 - Angels In Amplifiers - I&#39;m Alright/vocals.wav  
  inflating: DSD100subset/Sources/Dev/055 - Angels In Amplifiers - I&#39;m Alright/bass.wav  
  inflating: DSD100subset/Sources/Dev/055 - Angels In Amplifiers - I&#39;m Alright/drums.wav  
  inflating: DSD100subset/Sources/Dev/055 - Angels In Amplifiers - I&#39;m Alright/other.wav  
  inflating: DSD100subset/Sources/Test/049 - Young Griffo - Facade/bass.wav  
  inflating: DSD100subset/Sources/Test/049 - Young Griffo - Facade/vocals.wav  
  inflating: DSD100subset/Sources/Test/049 - Young Griffo - Facade/other.wav  
  inflating: DSD100subset/Sources/Test/049 - Young Griffo - Facade/drums.wav  
  inflating: DSD100subset/Sources/Test/005 - Angela Thomas Wade - Milk Cow Blues/vocals.wav  
  inflating: DSD100subset/Sources/Test/005 - Angela Thomas Wade - Milk Cow Blues/drums.wav  
  inflating: DSD100subset/Sources/Test/005 - Angela Thomas Wade - Milk Cow Blues/other.wav  
  inflating: DSD100subset/Sources/Test/005 - Angela Thomas Wade - Milk Cow Blues/bass.wav  
  inflating: DSD100subset/Mixtures/Test/005 - Angela Thomas Wade - Milk Cow Blues/mixture.wav  
  inflating: DSD100subset/Mixtures/Test/049 - Young Griffo - Facade/mixture.wav  
  inflating: DSD100subset/Mixtures/Dev/055 - Angels In Amplifiers - I&#39;m Alright/mixture.wav  
  inflating: DSD100subset/Mixtures/Dev/081 - Patrick Talbot - Set Me Free/mixture.wav  
  inflating: DSD100subset/dsd100subset.txt  
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="load-the-dataset">
<h1>Load the dataset.<a class="headerlink" href="#load-the-dataset" title="Link to this heading">#</a></h1>
<p>We will use the DSD100Dataset class from the automix.data module.
We load data at 44.1KHz sample rate. Lets have the train length = 65536 frames
We will split the dataset to have the first four examples as train and the rest as test; this is indicated using indices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_frames</span> <span class="o">=</span> <span class="mi">65536</span>
<span class="n">sample_rate</span> <span class="o">=</span> <span class="mi">44100</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">DSD100Dataset</span><span class="p">(</span>
    <span class="s2">&quot;./DSD100subset&quot;</span><span class="p">,</span>
    <span class="n">num_frames</span><span class="p">,</span>
    <span class="n">sample_rate</span><span class="p">,</span>
    <span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="n">num_examples_per_epoch</span><span class="o">=</span><span class="mi">100</span><span class="p">,)</span>

<span class="c1">#Define the dataloader</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">persistent_workers</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|| 4/4 [00:00&lt;00:00, 4095.00it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 4 mixes. Using 4 in this subset.
&lt;torch.utils.data.dataloader.DataLoader object at 0x7fe9669f5460&gt;
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>Lop over the dataloader to load examples for batch size of 1.
We will see the shape of the loaded data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,(</span> <span class="n">stems</span><span class="p">,</span> <span class="n">mix</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Stems shape: &quot;</span><span class="p">,</span> <span class="n">stems</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mix shape: &quot;</span><span class="p">,</span> <span class="n">mix</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pad shape: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pad</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pad: &quot;</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Stems shape:  torch.Size([1, 8, 65536])
Mix shape:  torch.Size([1, 2, 65536])
Pad shape:  1
Pad:  tensor([[False, False, False, False, False, False, False, False]])
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./part_3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="01_inference.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Inference</p>
      </div>
    </a>
    <a class="right-next"
       href="03_models.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Datasets for automix systems</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#listed-below-are-few-of-the-advised-variables-that-you-should-define-in-the-dataset-class-definition">Listed below are few of the advised variables that you should define in the dataset class definition:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-processing-advice-for-loading-multitrack-data">Pre-processing advice for loading multitrack data:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enst-drums">ENST Drums</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dsd100-dataset">DSD100 dataset</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#medleydb-dataset">MedleyDB Dataset</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-dataset">Load the dataset.</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Christian J. Steinmetz, Soumya Sai Vanka, Marco Martnez, Gary Bromham
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>