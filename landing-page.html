
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Deep Learning for Automatic Mixing &#8212; Deep Learning for Automatic Mixing</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Music Production" href="part_1/01_music-production.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep Learning for Automatic Mixing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1 current active">
                <a class="reference internal" href="#">
                    Deep Learning for Automatic Mixing 
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Audio Engineering
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="part_1/01_music-production.html">
   Music Production
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="part_1/music-production/01_mixing.html">
     Mixing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="part_1/music-production/02_equalization.html">
     Equalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="part_1/music-production/03_reveberation.html">
     Reverberation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="part_1/music-production/04_compression.html">
     Compression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="part_1/music-production/05_aesthetics.html">
     Aesthetics
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Automatic Mixing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="part_2/01_imp.html">
   Intelligent Music Production
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part_2/02_problem.html">
   Problem Formulation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="part_2/03_methods.html">
   Methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="part_2/methods/01_mixwaveunet.html">
     Mix-Wave-U-Net
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="part_2/methods/02_dmc.html">
     Differentiable Mixing Console
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part_2/04_loss-functions.html">
   Loss Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part_2/05_diffsp.html">
   Differentiable signal processing
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Implementation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="part_3/01_inference.html">
   Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part_3/02_datasets.html">
   Datasets for automix systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part_3/03_models.html">
   Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part_3/04_training.html">
   Training
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Evaluation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="part_4/01_metrics.html">
   Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part_4/05_evaluate.html">
   Evaluation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Conclusion
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="part_5/01_future-directions.html">
   Future Directions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part_5/02_conclusion.html">
   Conclusions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part_5/03_references.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/dl4am/tutorial"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/dl4am/tutorial/issues/new?title=Issue%20on%20page%20%2Flanding-page.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/landing-page.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   Motivation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#about-the-authors">
   About the authors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#software">
   Software
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#citing-this-book">
   Citing this book
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#note">
   Note
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Deep Learning for Automatic Mixing </h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   Motivation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#about-the-authors">
   About the authors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#software">
   Software
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#citing-this-book">
   Citing this book
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#note">
   Note
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="deep-learning-for-automatic-mixing-book">
<h1>Deep Learning for Automatic Mixing <img alt="Book" src="_images/logo.png" /><a class="headerlink" href="#deep-learning-for-automatic-mixing-book" title="Permalink to this headline">#</a></h1>
<p>This is a web book written for a <a class="reference external" href="https://ismir2022.ismir.net/program/tutorials/">tutorial session</a> of <a class="reference external" href="https://ismir2022.ismir.net/index">the 23rd International Society for Music Information Retrieval Conference</a>, Dec 4-8, 2022 held at Bengaluru, India in hybrid format. The <a class="reference external" href="https://ismir.net/">ISMIR conference</a> is the world’s leading research forum on processing, searching, organising and accessing music-related data.</p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">#</a></h2>
<p>Mixing is a central task within audio post-production where expert knowledge is required to deliver professional quality content, encompassing both technical and creative considerations.
Recently, deep learning approaches have been introduced that aim to address this challenge by generating a cohesive mixture of a set of recordings as would an audio engineer.
These approaches leverage large-scale datasets and therefore have the potential to outperform traditional approaches based on expert systems, but bring their own unique set of challenges.
In this tutorial, we begin by providing an introduction to the mixing process from the perspective of an audio engineer, along with a discussion of the tools used in the process from a signal processing perspective.
We then discuss a series of recent deep learning approaches and relevant datasets, providing code to build, train, and evaluate these systems.
Future directions and challenges will be discussed, including new deep learning systems, evaluation methods, and approaches to address dataset availability.
Our goal is to provide a starting point for researchers working in MIR who have little to no experience in audio engineering so they can easily begin addressing problems in this domain.
In addition, our tutorial may be of interest to researchers outside of MIR, but with a background in audio engineering or signal processing, who are interested in gaining exposure to current approaches in deep learning.</p>
</section>
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">#</a></h2>
<p>Music mixing is a crucial task within audio post-production where expert knowledge is required to deliver professional music content <span id="id1">[]</span>.
This task encompasses both technical and creative considerations in the process of combining individual sources into a mixture, often involving the use of audio processors such as equalization, dynamic range compression, panning, and reverberation<span id="id2">[<a class="reference internal" href="part_5/03_references.html#id29" title="Thomas Wilmering, David Moffat, Alessia Milo, and Mark B Sandler. A history of audio effects. Applied Sciences, 10(3):791, 2020.">WMMS20</a>]</span>.<br />
Due to this complexity, the field of intelligent music production (IMP) <span id="id3">[<a class="reference internal" href="part_5/03_references.html#id6" title="Ryan Stables, Joshua D. Reiss, and Brecht De Man. Intelligent Music Production. Focal Press, 2019.">SRDM19</a>]</span> has focused on the design of systems that automate tasks in audio engineering.
These systems aim to lower the difficulty in creating productions by novice users, as well as expedite or extend the workflow for professionals <span id="id4">[<a class="reference internal" href="part_5/03_references.html#id7" title="David Moffat and Mark B Sandler. Approaches in intelligent music production. Arts, 8(5):14, September 2019.">MS19b</a>]</span>.</p>
<p>In recent years, researchers have investigated automatic mixing, the task of constructing a system to automatically create a cohesive mixture from a set of recordings as would a human audio engineer<span id="id5">[]</span>.
Existing approaches include adaptive signal processing<span id="id6">[<a class="reference internal" href="part_5/03_references.html#id12" title="Enrique Perez-Gonzalez and Joshua Reiss. Automatic gain and fader control for live mixing. In 2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, 1–4. IEEE, 2009.">PGR09</a>]</span>, rule-based <span id="id7">[<a class="reference internal" href="part_5/03_references.html#id35" title="Brecht De Man and Joshua D Reiss. A knowledge-engineered autonomous mixing system. In 135th Audio Engineering Society Convention. Audio Engineering Society, 2013.">DMR13</a>]</span>, machine learning<span id="id8">[<a class="reference internal" href="part_5/03_references.html#id28" title="Dave Moffat and Mark Sandler. Machine learning multitrack gain mixing of drums. In 147th Audio Engineering Society Convention. 2019.">MS19a</a>]</span>, and most recently deep learning<span id="id9">[<a class="reference internal" href="part_5/03_references.html#id30" title="Marco A Martínez-Ramírez, Daniel Stoller, and David Moffat. A deep learning approach to intelligent drum mixing with the Wave-U-Net. Journal of the Audio Engineering Society, 2021.">MartinezRamirezSM21</a>, <a class="reference internal" href="part_5/03_references.html#id31" title="Christian J Steinmetz, Jordi Pons, Santiago Pascual, and Joan Serrà. Automatic multitrack mixing with a differentiable mixing console of neural audio effects. In ICASSP. IEEE, 2021.">SPPSerra21</a>]</span> approaches.
While deep learning approaches that leverage large-scale datasets have the potential to outperform traditional approaches, their performance is still far from professional audio engineers motivating further investigation in the design and evaluation of these systems.</p>
<p>While applications of deep learning in MIR have continued to broaden, applications in audio engineering still remain under-investigated leaving a number of open research questions.
However, the growing body of research in MIR tasks such as music source separation<span id="id10">[<a class="reference internal" href="part_5/03_references.html#id45" title="Fabian-Robert Stöter, Stefan Uhlich, Antoine Liutkus, and Yuki Mitsufuji. Open-unmix-a reference implementation for music source separation. Journal of Open Source Software, 4(41):1667, 2019.">StoterULM19</a>]</span>, music generation<span id="id11">[<a class="reference internal" href="part_5/03_references.html#id46" title="Jean-Pierre Briot, Gaëtan Hadjeres, and François-David Pachet. Deep learning techniques for music generation–a survey. arXiv:1709.01620, 2017.">BHP17</a>]</span>, and music classification<span id="id12">[<a class="reference internal" href="part_5/03_references.html#id47" title="Minz Won, Andres Ferraro, Dmitry Bogdanov, and Xavier Serra. Evaluation of cnn-based automatic music tagging models. In Proc. of 17th Sound and Music Computing. 2020.">WFBS20</a>]</span> provide insights into advancing applications in audio engineering.
Therefore, the ISMIR community stands to benefit from a tutorial that introduces the basics and intricacies of music mixing as along with the discussion on existing approaches and open challenges.
Our hope is to raise awareness of MIR from the perspective of audio engineering and further stimulate research interest in this area within the MIR community.</p>
</section>
<section id="about-the-authors">
<h2>About the authors<a class="headerlink" href="#about-the-authors" title="Permalink to this headline">#</a></h2>
<a class="reference internal image-reference" href="_images/cjs.jpeg"><img alt="Christian Steinmetz" class="align-left" src="_images/cjs.jpeg" style="width: 100px;" /></a>
<p><a class="reference external" href="https://www.christiansteinmetz.com/"><strong>Christian J. Steinmetz</strong></a> is PhD researcher working with Prof. Joshua D. Reiss within the Centre for Digital Music at Queen Mary University of London. He researches applications of machine learning in audio with a focus on differentiable signal processing. Currently, his research revolves around applications in high fidelity audio and music production, which involves enhancing audio recordings, intelligent systems for audio engineering, as well as applications that augment and extend creativity. He has worked as a Research Scientist Intern at Adobe, Facebook Reality Labs, and Dolby Labs. Christian holds a BS in Electrical Engineering and BA in Audio Technology from Clemson University, as well as an MSc in Sound and Music Computing from the Music Technology Group at Universitat Pompeu Fabra.</p>
<a class="reference internal image-reference" href="_images/ssv.jpeg"><img alt="CSoumya Sai Vanka" class="align-left" src="_images/ssv.jpeg" style="width: 100px;" /></a>
<p><a class="reference external" href="https://www.saisoumya.com/"><strong>Soumya Sai Vanka</strong></a> is a first year PhD researcher at the Centre for Digital Music, Queen Mary University of London. She is part of the AI and Music, Centre for Doctoral Training. Her research focus is mainly on exploring the idea of Music Mix similarity, Music Mix Style transfer, and Intelligent Multitrack Mixing using Self-Supervised, Semi-Supervised, and Unsupervised Learning architectures. She also writes music, produces and plays saxophone. Her educational background is a mixture of Masters in Physics and Courses in Music Production.</p>
<a class="reference internal image-reference" href="_images/mamr.jpeg"><img alt="Marco Martínez" class="align-left" src="_images/mamr.jpeg" style="width: 100px;" /></a>
<p><a class="reference external" href="https://m-marco.com/"><strong>Marco Martínez</strong></a> is music technology researcher at Sony in the Tokyo R&amp;D center, where he is part of the Creative AI Lab. His research interests lie at the intersection of machine learning, digital signal processing, and intelligent music production, with a primary focus on deep learning architectures for music processing tasks. Previously, he was an audio research intern at Adobe and received his PhD from the Centre for Digital Music at Queen Mary University of London. He has a MSc in digital signal processing from the University of Manchester, UK, and a BSc in electronic engineering from La Universidad de Los Andes, Colombia. Marco also has a background in music production and mixing engineering.</p>
<a class="reference internal image-reference" href="_images/gb.jpeg"><img alt="Gary Bromham*" class="align-left" src="_images/gb.jpeg" style="width: 100px;" /></a>
<p><a class="reference external" href="https://c4dm.eecs.qmul.ac.uk/"><strong>Gary Bromham</strong></a> is a part-time PhD researcher at Queen Mary University of London, researching the role that traditional studio paradigms and retro aesthetics play in intelligent music production systems (2016 -). He has several publications in this field and has contributed a chapter to the recent Routledge publication, ‘Perspectives on Music Production: Mixing Music’ (2017). He was also a research assistant on the EPSRC funded project called FAST (Fusing Audio and Semantic Technologies) where he is employed as an industry advisor (2017 - 2020). In addition to his research interests, Gary is a practising music producer, songwriter and audio engineer, with over 30 years’ experience (1989 - 2020). He has worked with artists as diverse as Bjork, Wham, Blur and U2, during a period that has witnessed several technological changes. Gary is well versed in most popular music making software and has extensive knowledge of using analog hardware, acting as a product designer and specialist for the renowned mixing desk company, Solid State Logic. He is also a frequent guest lecturer and external advisor at several universities in the UK, Norway and Sweden; speaking on songwriting, music production aesthetics and audio engineering and bringing some of his extensive knowledge and experience to both Undergraduate and Master’s degree level programs.</p>
</section>
<section id="software">
<h2>Software<a class="headerlink" href="#software" title="Permalink to this headline">#</a></h2>
</section>
<section id="citing-this-book">
<h2>Citing this book<a class="headerlink" href="#citing-this-book" title="Permalink to this headline">#</a></h2>
<p>If you use this book or any of accompanying code in your work please consider citing this book.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@book</span><span class="p">{</span><span class="n">steinmetz2022automix</span><span class="p">,</span>
    <span class="n">Author</span> <span class="o">=</span> <span class="p">{</span><span class="n">Steinmetz</span><span class="p">,</span> <span class="n">Christian</span> <span class="n">J</span><span class="o">.</span> <span class="ow">and</span> <span class="n">Vanka</span><span class="p">,</span> <span class="n">Soumya</span> <span class="n">Sai</span> <span class="ow">and</span> <span class="n">Martínez</span> <span class="n">Ramírez</span><span class="p">,</span> <span class="n">Marco</span> <span class="n">A</span><span class="o">.</span> <span class="ow">and</span> <span class="n">Bromham</span><span class="p">,</span> <span class="n">Gary</span><span class="p">},</span>
    <span class="n">Month</span> <span class="o">=</span> <span class="n">Dec</span><span class="o">.</span><span class="p">,</span>
    <span class="n">Publisher</span> <span class="o">=</span> <span class="p">{</span><span class="n">ISMIR</span><span class="p">},</span>
    <span class="n">Title</span> <span class="o">=</span> <span class="p">{</span><span class="n">Deep</span> <span class="n">Learning</span> <span class="k">for</span> <span class="n">Automatic</span> <span class="n">Mixing</span><span class="p">},</span>
    <span class="n">Year</span> <span class="o">=</span> <span class="mi">2022</span><span class="p">,</span>
    <span class="n">Url</span> <span class="o">=</span> <span class="p">{</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">dl4am</span><span class="o">.</span><span class="n">github</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">tutorial</span><span class="p">},</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="note">
<h2>Note<a class="headerlink" href="#note" title="Permalink to this headline">#</a></h2>
<p>You can download a pdf of this book from <span class="xref myst">arXiv</span>. If the pdf is not up-to-date, you can <a class="reference external" href="https://github.com/dl4am/tutorial/scripts/build-book.sh">build it by yourself</a> on your local machine.</p>
</section>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='right-next' id="next-link" href="part_1/01_music-production.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Music Production</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Christian Steinmetz, Soumya Sai Vanka, Marco Martínez, Gary Bromham<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>